{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/earthinversion/mtuq_scoped_workshop_2024/blob/main/SCOPED_2024_MTUQ_Workshop.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Welcome to the MTUQ 2024 workshop!\n",
        "\n",
        "This workshop is presented as part of the SCOPED 2024 workshop series, which takes place in person at the University of Washington, and online worldwide.\n",
        "\n",
        "\n",
        "## Schedule\n",
        "The detailed schedule for the workshop series is available [here](https://seisscoped.org/workshop-2024/). All parts of the workshop will be uploaded to YouTube later on.\n",
        "\n",
        "\n",
        "## Contact Information\n",
        "For any questions or additional information, feel free to contact me:\n",
        "\n",
        "**Julien Thurin**  \n",
        "Postdoctoral Fellow, University of Alaska Fairbanks  \n",
        "**Email:** [jthurin@alaska.edu](mailto:jthurin@alaska.edu)\n",
        "## Additional Information\n",
        "- [MTUQ repository](https://github.com/uafgeotools/mtuq)\n",
        "- **Last Modified:** May 21, 2024"
      ],
      "metadata": {
        "id": "1uCfXON4S2Xj"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vf2yoO62j8lJ"
      },
      "source": [
        "# Jupyter Notebook <a name=\"1\"></a>\n",
        "\n",
        "The document you are reading is a  [Jupyter notebook](https://jupyter.org/), hosted in Colaboratory. It is not a static page, but an interactive environment that lets you write and execute code in Python and other languages. There are two main cell types in a notebook:\n",
        "\n",
        "\n",
        "*   A **code cell** contains code to be executed in the kernel and displays its output below.\n",
        "*   A **markdown cell** contains text formatted using Markdown and displays its output in-place when it is run.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fZOiPfGvkBuX"
      },
      "source": [
        "## Code cells\n",
        "For example, here is a **code cell** with a short Python script that computes a value, stores it in a variable, and prints the result:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dvb1BJrikDwD"
      },
      "outputs": [],
      "source": [
        "workshop_duration = 3 * 60 * 60\n",
        "print (\"Workshop duration: \", workshop_duration, \"seconds\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sy2__8yAkGAk"
      },
      "source": [
        "To execute the code in the above cell, select it and execute the contents in the following ways:\n",
        "\n",
        "* Click the **Play icon** in the left gutter of the cell;\n",
        "* Type **Cmd/Ctrl+Enter** to run the cell in place;\n",
        "* Type **Shift+Enter** to run the cell and move focus to the next cell (adding one if none exists)\n",
        "* Type **Alt+Enter** to run the cell and insert a new code cell immediately below it.\n",
        "\n",
        "There are additional options for running some or all cells in the **Runtime** menu.\n",
        "\n",
        "All cells modify the same **global** state, so variables that you define by executing a cell can be used in other cells:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3r32UpatkQtO"
      },
      "outputs": [],
      "source": [
        "workshop_duration = workshop_duration + (15 * 60)\n",
        "print (\"Workshop duration: \", workshop_duration, \"seconds\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e0ndLCCakVkK"
      },
      "source": [
        "You can also execute **bash commands** by adding an **\\!** sign at the start of the line:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3cTqvsjOkYNJ"
      },
      "outputs": [],
      "source": [
        "!echo Hello World"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OHQe08VMkatE"
      },
      "source": [
        "**Magics** are shorthand annotations that change how a cell's text is executed. To learn more, see [Jupyter's magics page](http://nbviewer.jupyter.org/github/ipython/ipython/blob/1.x/examples/notebooks/Cell%20Magics.ipynb)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "94zJBm6rkdoU"
      },
      "outputs": [],
      "source": [
        "%%html\n",
        "<html lang=\"en\">\n",
        "<head><meta charset=\"UTF-8\"><title>Wave Effect on Each Letter</title>\n",
        "<style>@keyframes wave {0%, 100% {transform: translateY(-5px);} 50% {transform: translateY(5px);}}\n",
        "@keyframes rainbow {0% {color: red;} 15% {color: orange;} 30% {color: yellow;} 45% {color: green;} 60% {color: blue;} 75% {color: indigo;} 90% {color: violet;} 100% {color: red;}}\n",
        ".letter {display: inline-block; animation: wave 2s infinite, rainbow 10s infinite; animation-delay: calc(var(--i) * 0.1s);}\n",
        "marquee {width: 80%; font-size: 24px; font-weight: bold;}</style></head>\n",
        "<body><marquee behavior=\"scroll\" direction=\"left\">\n",
        "<span class=\"letter\" style=\"--i:0;\">~</span><span class=\"letter\" style=\"--i:1;\">~</span><span class=\"letter\" style=\"--i:2;\">~</span><span class=\"letter\" style=\"--i:3;\"> </span><span class=\"letter\" style=\"--i:4;\">M</span><span class=\"letter\" style=\"--i:5;\">T</span><span class=\"letter\" style=\"--i:6;\">U</span><span class=\"letter\" style=\"--i:7;\">Q</span><span class=\"letter\" style=\"--i:8;\"> </span><span class=\"letter\" style=\"--i:9;\">w</span><span class=\"letter\" style=\"--i:10;\">o</span><span class=\"letter\" style=\"--i:11;\">r</span><span class=\"letter\" style=\"--i:12;\">k</span><span class=\"letter\" style=\"--i:13;\">s</span><span class=\"letter\" style=\"--i:14;\">h</span><span class=\"letter\" style=\"--i:15;\">o</span><span class=\"letter\" style=\"--i:16;\">p</span><span class=\"letter\" style=\"--i:17;\"> </span><span class=\"letter\" style=\"--i:18;\">2</span><span class=\"letter\" style=\"--i:19;\">0</span><span class=\"letter\" style=\"--i:20;\">2</span><span class=\"letter\" style=\"--i:21;\">4</span><span class=\"letter\" style=\"--i:22;\"> </span><span class=\"letter\" style=\"--i:23;\">~</span><span class=\"letter\" style=\"--i:24;\">~</span><span class=\"letter\" style=\"--i:25;\">~</span>\n",
        "</marquee></body>\n",
        "</html>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CUWVkdI9myKD"
      },
      "source": [
        "Google Colab supports. the use of `gdown`, which is a very handy function that allows downloading from any publicly-shared Google-drive link. While you could in theory use `curl` or `wget`, they sometimes fail with Google drive security notice, or recursive download with large number of files."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ohWAgH89km5C"
      },
      "source": [
        "## Markdown cells\n",
        "\n",
        "This is a **markdown cell**. You can **double-click** to edit this cell. Text cells\n",
        "use markdown syntax. To learn more, see the [markdown\n",
        "guide](/notebooks/markdown_guide.ipynb).\n",
        "\n",
        "You can also add math to text cells using [LaTeX](http://www.latex-project.org/)\n",
        "to be rendered by [MathJax](https://www.mathjax.org). Just place the statement\n",
        "within a pair of **\\$** signs.\n",
        "\n",
        "For example `$\\sqrt{3x-1}+(1+x)^2$` becomes\n",
        "$\\sqrt{3x-1}+(1+x)^2.$\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n8Gxw3DPkxAb"
      },
      "source": [
        "# Google Colaboratory <a name=\"2\"></a>\n",
        "\n",
        "Google Colab is a hosted **Jupyter Notebook** service that lets you write, run and share Python code in Google Drive. You can think of colab as a Jupyter Notebook stored on the **cloud**. Colab connects the notebook to a cloud-based runtime, meaning you can execute Python code without any setup or impact on your machine.\n",
        "\n",
        "Colab offers several code snippets for typical Python tasks available on the sidebar.\n",
        "\n",
        "## Usage considerations\n",
        "\n",
        "*   Google colab is free to use.\n",
        "*   Paid options (Colab Pro and Pro+) allow to get better machines.\n",
        "*   The runtime will reset after 12 hours of continuous computation or if IDLE for too long (the exact idle timeout can vary but is generally around 90 minutes for the free tier).\n",
        "*   When the runtime resets you lose all the uploaded / saved files and environment.\n",
        "*   Resources are assigned dynamically according to the type of work you are doing.\n",
        "*   You can use applications such as ngrok to build a network tunnel and access your virtual machine from outside.\n",
        "*   Manage your active sessions with Runtime → Manage sessions\n",
        "*   To avoid loosing all your data when the runtime resets connect your google drive to Colab and save checkpoints\n",
        "\n",
        "### Integration with Drive\n",
        "\n",
        "Colaboratory is integrated with Google Drive. It allows you to share, comment, and collaborate on the same document with multiple people:\n",
        "\n",
        "* The **SHARE** button (top-right of the toolbar) allows you to share the notebook and control permissions set on it.\n",
        "\n",
        "* **File->Make a Copy** creates a copy of the notebook in Drive.\n",
        "\n",
        "* **File->Save** saves the File to Drive. **File->Save and checkpoint** pins the version so it doesn't get deleted from the revision history.\n",
        "\n",
        "* **File->Revision history** shows the notebook's revision history."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I8Xc85TWX1Ku"
      },
      "source": [
        "# Introduction to Moment tensor inversion with the Cut-and-Paste method\n",
        "\n",
        "In this brief introduction, we will see what the moment tensor inversion problem is about. This should cover all the theory you should be familiar with before handling MTUQ, starting with:\n",
        "\n",
        "### The seismic moment tensor\n",
        "\n",
        "The seismic moment tensor $\\mathbf{M}$ is a mathematical representation of the motion applied to a point-sized seismic source. It is a $3 \\times 3$ second-order symmetric tensor with 6 independent parameters.\n",
        "\n",
        "<figure>\n",
        "<center>\n",
        "<img src=\"https://drive.google.com/uc?id=1L-LPgIGjQjJmX45IM1dDeSagvuAEDkNf\" width=\"400\" height=\"400\" alt=\"Representation of the double couple on a fault\">\n",
        "<figcaption>Representation of the moment tensor $\\mathbf{M}$ components in terms of linear vector dipoles and force couples. From <a href=\"https://www.wiley.com/en-au/An+Introduction+to+Seismology%2C+Earthquakes%2C+and+Earth+Structure-p-9780865420786\">Stein & Wysession (2002)</a>.</figcaption>\n",
        "</center>\n",
        "</figure>\n",
        "\n",
        "In the ideal case of a motion applied onto a perfect fault-plane, it can be represented by a supperposition of force-couples or dipoles (with zero net-torque):\n",
        "\n",
        "<figure>\n",
        "<center>\n",
        "<img src=\"https://drive.google.com/uc?id=1nDiqFdipVnfdp3Z2AiWuo9xxlYSZJBxJ\" width=\"400\" height=\"140\" alt=\"Representation of the double couple on a fault\">\n",
        "<figcaption>Motion on an ideal fault plane represented as double-couples. From <a href=\"https://www.wiley.com/en-au/An+Introduction+to+Seismology%2C+Earthquakes%2C+and+Earth+Structure-p-9780865420786\">Stein & Wysession (2002)</a>.</figcaption>\n",
        "</center>\n",
        "</figure>\n",
        "\n",
        "Therefore, by estimating the moment tensor parameters for seismic sources that fall into the point-source approximation we can learn about their geometrical properties, and the general motion that was applied to the subsurface - generating seismic waves.\n",
        "\n",
        "---\n",
        "\n",
        "A moment tensor can be conveniently represented as the so-called *beachball*, which is a representation of the P-wave first motions in 3D space (binary representation of the P-waves radiation pattern). The color of the beachball reflects the direction of motion applied in different directions. It is generally white for motion pointing inward and black (or color shaded) for motion pointing outward of the unit sphere.\n",
        "\n",
        "<figure>\n",
        "<center>\n",
        "<img src=\"https://drive.google.com/uc?id=1BbBCibwB3CD6p3N0h9B7cnV2OS0PM3xt\" width=\"400\" height=\"400\" alt=\"Representation of the double couple on a fault\">\n",
        "<figcaption>Vector field representation of the motion associated with double-couple point source. represented as a 'beachball'. Courtesy of <a href=\"https://mxrap.com/2019/07/26/moment-tensors-a-practical-guide/\">Stuart Tierney</a>.</figcaption>\n",
        "</center>\n",
        "</figure>\n",
        "\n",
        "Most of the time, moment tensor \"beachballs\" are visualized as 2D diagrams. These diagrams are stereonet projections of the lower hemisphere of the unit sphere, as seen from above in a map view. This representation allows for easier interpretation and analysis, as it conveys the general motion on a fault at a glance, or the source type in the case of non double-couple sources.\n",
        "\n",
        "<figure>\n",
        "<center>\n",
        "<img src=\"https://s3.amazonaws.com/pnsn-cms-uploads/attachments/000/000/782/original/fc3a5caddf34f183f09a2382cb05136d\" width=\"400\" alt=\"Representation of the double couple on a fault\">\n",
        "<figcaption>Common double couple moment tensor and associated fault block-models <a href=\"https://www.usgs.gov/media/images/schematic-diagram-focal-mechanism\">USGS</a>.</figcaption>\n",
        "</center>\n",
        "</figure>\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "### Moment tensor parameterization and the Lune diagram\n",
        "\n",
        "Moment tensors attributes can be broadly defined as *source type* and *orientation*, which are both informed by the geometrical properties of the tensor. Given a moment tensor $\\mathbf{M}$, whose eigvenvalues $(\\lambda_1, \\lambda_2, \\lambda_3)$ satisfy $\\lambda_1 \\geq \\lambda_2 \\geq \\lambda_3$, we can represent a moment tensor as its eigendecomposition:\n",
        "\n",
        "$\\mathbf{M} = \\mathbf{U \\Lambda U}^T$\n",
        "\n",
        "where $\\mathbf{U}$ contains the eigenvectors that satisfies $\\mathbf{UU}^T = \\mathbf{I}$, and $\\mathbf{\\Lambda}$ is the diagonal matrix containing the eigenvalue triple in descending order.\n",
        "\n",
        "With this decomposition in mind, we see that $\\mathbf{U}$ encodes the source orientation (the tensor's eigenframe), and $\\mathbf{\\Lambda}$ encodes the source type. From this decomposition stems a very natural way of representing source-types, by projecting the tensor position on the eigenvalue lune:\n",
        "\n",
        "<figure>\n",
        "<center>\n",
        "<img src=\"https://drive.google.com/uc?id=1tdne2Vce-VzBCryIcL_j1NC2iXjgpuGd\" width=\"600\" height=\"200\" alt=\"Representation of the double couple on a fault\">\n",
        "<figcaption>Definition of the eigenvalue lune as a set of ordered and normalized eigenvalues. From <a href=\"https://drive.google.com/file/d/1-B37EEHRp-ZpycFYVGj3TRUFOy3H0VoJ/view\">Tape & Tape 2019</a>.</figcaption>\n",
        "</center>\n",
        "</figure>\n",
        "\n",
        "In the following example, we show for 4 fixed eigenframes, how the moment-tensor source type changes as a function of $\\mathbf{\\Lambda}$ only:\n",
        "\n",
        "<figure>\n",
        "<center>\n",
        "<img src=\"https://drive.google.com/uc?id=1d8C61-mQsvGSjvnEKYexrELVuSXUvj5v\" width=\"600\" height=\"320\" alt=\"Representation of the double couple on a fault\">\n",
        "<figcaption>Moment-tensor source type plot for a set of 4 fixed source orientations. For a fixed orientation, the location on the eigenvalue lune controls the source type. From <a href=\"https://sites.google.com/alaska.edu/carltape/home/research/beachball_gallery?authuser=0\">Carl Tape</a> figure gallery.</figcaption>\n",
        "</center>\n",
        "</figure>\n",
        "\n",
        "In `MTUQ`, we adopt a moment-tensor parameterization that exploits the geometrical properties of the moment tensor so that we explore the moment-tensor space in a uniform manner. Instead of exploring the 6 parameters of the moment tensor directly, we will express moment tensors with the following set of coordinates:\n",
        "\n",
        "* $γ, δ$ for the eigenvalue triple, $γ$ being the lune longitude and $δ$ the lune colatitude,\n",
        "* $κ, σ, θ$ for the orientaion, where $κ$, $σ$, $θ$ are for strike, dip and, slip angles respectively.\n",
        "* $ρ$ gives the scalar seismic moment $M_0 = ρ \\sqrt{2}^{-1}$\n",
        "\n",
        "such that we have $\\mathbf{M}(ρ, γ, δ, κ, σ, θ)$.\n",
        "\n",
        "For more details, you can read <a href=\"https://drive.google.com/file/d/1s41vK795cncM_IeTI617Y3GaZ6mVbQhp/view\">Tape & Tape (2015)</a>.\n",
        "\n",
        "### Moment tensor inversion\n",
        "In `MTUQ` we solve the moment tensor inversion problem by finding the source that minimizes the following cost function:\n",
        "\n",
        "$C(\\mathbf{M}) = \\sum_{r=1}^{N} \\sum_{i=1}^{3} \\int_0^T \\left[d_i^r(t,\\mathbf{M}) - d_i^{r,obs}(t)\\right]^2 dt$\n",
        "\n",
        "which translates to the sum of least-squares waveform difference between the synthetic waveforms $d(t)$ and the observed data $d^{obs}(t)$ for N stations with 3 components.\n",
        "\n",
        "In order to speed up the optimization process, we rely on a set of pre-computed Green's functions $\\mathbf{G}^r$ between each source-receiver pair $r$, such that we can recast the problem as\n",
        "\n",
        "$C(\\mathbf{M}) = \\sum_{r=1}^{N} \\sum_{i=1}^{3} \\int_0^T \\left[\\mathbf{G}_i^r \\mathbf{m} - d_i^{r,obs}\\right]^2 dt$\n",
        "\n",
        "where the time dependency has been dropped for convenience, and $\\mathbf{m}$ is a vector containing the 6 independent parameters of the Moment tensor $\\mathbf{M}$. Using pre-computed Green's functions allows the rapid evaluation of the residual term, which we simplify as:\n",
        "\n",
        "$\\mathbf{r} = \\mathbf{Gm} - \\mathbf{d}$\n",
        "\n",
        "which is less expensive than explicitly modeling the waveform for each source in a given earth model.\n",
        "\n",
        "### The Cut-and-paste method\n",
        "\n",
        "The algorithm underlying `MTUQ` is known as the \"cut-and-paste\" (CAP)method of <a href=\"https://doi.org/10.1785/BSSA0860051634\"> Zhu & Helmberger (1996)</a>.\n",
        "\n",
        "The main goal of the CAP method is to mitigate the effects of 3-D velocity structures that are unaccounted for with a 1D reference model (or an inexact 3D model).\n",
        "\n",
        "It does so by splitting all the data into specific window groups (typically P-waves and Surface waves) and allowing a time-shift window for the synthetics. Within this allowable time-shift window, a cross-correlation is performed between $d_{syn}$ and $d_{obs}$, and the residual is computed only for the maximum cross-correlation value (when signals are supposedly aligned).\n",
        "\n",
        "<figure>\n",
        "<center>\n",
        "<img src=\"https://drive.google.com/uc?id=1n3pKpm_zTqIwiMKsPUcC-aWuUbUqq7LR\" width=\"600\" height=\"320\" alt=\"Representation of the double couple on a fault\">\n",
        "<figcaption>Illustration of the cut and paste method.</figcaption>\n",
        "</center>\n",
        "</figure>\n",
        "\n",
        "We do this for each data group (P, Rayleigh, Love waves), for each station and each component (Z-R-T), and return one misfit value corresponding to the maximum cross-correlation value.\n",
        "\n",
        "---\n",
        "\n",
        "This should cover most of the basics, let's move to the code now!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G0hP2-08XdnQ"
      },
      "source": [
        "# 1.0.0 Setting up your first Double-Couple inversion <a name=\"2\"></a>\n",
        "\n",
        "In the following, we will work through all the basic ingredients to run your first Double-Couple inversion in MTUQ.\n",
        "This tutorial is based on the example provided in the MTUQ package, which can be found in the `mtuq/examples/` directory.\n",
        "\n",
        "We will work with the 2009-04-07 Mw 4.5 earthquake recorded near Anchorage. The data is provided in the `mtuq/examples/data/` directory."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "9yvc95JURnaz"
      },
      "outputs": [],
      "source": [
        "#@title 1.1.0 We'll install MTUQ and load some data in the background...\n",
        "%%capture\n",
        "import os\n",
        "import time\n",
        "!git clone -b uq_matplotlib https://github.com/uafgeotools/mtuq.git --depth 1\n",
        "!bash /content/mtuq/data/examples/unpack.bash\n",
        "%pip install git+https://github.com/rmodrak/instaseis.git /content/mtuq pysep-adjtomo\n",
        "time.sleep(5)\n",
        "os.kill(os.getpid(), 9)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ZVkfI6nSOyd"
      },
      "source": [
        "The cell above will **download, install, and restart the Python \"runtime\"** (the Python interpreter that runs in each code cell of this notebook). After completion, the play icon will turn **<font color='red'>red</font>**, as if an error occurred: **this is expected** as the cell forces the runtime to restart, and the interpreter perceives it as an error. It should take about **1~2 minutes**.\n",
        "\n",
        "When the play button turns **<font color='red'>red</font>**, we can move forward!\n",
        "\n",
        "Because the previous cell restarts the runtime, you won't be able to do \"Runtime > Run All\". From this point, however, you can do \"Runtime > Run after\" (*note that the grid-visualization widget will not respond while the Runtime is busy*).\n",
        "\n",
        "The next cell is also going to load a couple of additional utility functions setup for this notebook, which are non-standar to MTUQ, just to make things a bit more interactive. We'll also be downloading pre-bundled Green's functions instead of downloading them from [syngine](http://ds.iris.edu/ds/products/syngine/)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7aR2gnGuT-pi"
      },
      "source": [
        "<!-- The cell above is loading a map and caching Green's tensors in advance instead of downloading them from syngine (we will use Green's function pre-downloaded and stored on a public drive for the first example) -->"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "Kg31vwDdRlrM"
      },
      "outputs": [],
      "source": [
        "#@title 1.2.0 Loading additional tools for the workshop...\n",
        "%%capture\n",
        "# # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # #\n",
        "# # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # #\n",
        "#                 🌟 🌟 🌟 🌟 Hey, Curious Explorer! 🌟 🌟 🌟 🌟          #\n",
        "#  You've found the utility functions! This part of the notebook is all     #\n",
        "#  about making things run smoothly and interactively. Not essential to the #\n",
        "#  main workshop, but definitely fun for a sneak peek if you like digging   #\n",
        "#          a little deeper. Enjoy the behind-the-scenes magic!              #\n",
        "#                                                                           #\n",
        "# (I recognize this is not the prettiest display of code, but some of you   #\n",
        "#          might be interested in what was purposefully set aside).         #\n",
        "# # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # #\n",
        "# # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # #\n",
        "\n",
        "# # # Google colab is a bit rigid in terms of environment, and we need to change\n",
        "# # # where the syngine green's functions will be downloaded.\n",
        "# # # Make sure the cache for syngine green's tensor is set at the right place\n",
        "import os\n",
        "os.environ['SYNGINE_CACHE'] = '/content/mtuq/data/greens_tensor/syngine/cache/'\n",
        "import numpy as np\n",
        "\n",
        "# # # Prevents matplotlib font manager warnings to display in the cells outputs\n",
        "import logging\n",
        "logging.getLogger('matplotlib.font_manager').disabled = True\n",
        "# # # Suppress specific obspy warnings\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"obspy.imaging.util\")\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"obspy.imaging.waveform\")\n",
        "\n",
        "# # # Some more warning suppression by modifying one of the file in the background...\n",
        "file_path = '/content/mtuq/examples/GridSearch.FullMomentTensor.py'\n",
        "lines_to_add = \"import logging\\nlogging.getLogger('matplotlib.font_manager').disabled = True\\n\"\n",
        "# # # Read, modify, and write back the file\n",
        "with open(file_path, 'r+') as file:\n",
        "    content = file.read()\n",
        "    shebang = '#!/usr/bin/env python\\n'\n",
        "    content = content.replace(shebang, shebang + lines_to_add)\n",
        "    file.seek(0)\n",
        "    file.write(content)\n",
        "    file.truncate()\n",
        "\n",
        "# # # Miscelaneous imports for the Follium map...\n",
        "# # # ... starting with under the hood data import using MTUQ classes and methods\n",
        "from mtuq import read, open_db, download_greens_tensors\n",
        "from mtuq.io.readers.SAC import read\n",
        "from mtuq.event import Origin\n",
        "from mtuq.graphics import plot_data_greens2, plot_beachball, plot_misfit_dc\n",
        "from mtuq.grid import DoubleCoupleGridRegular, FullMomentTensorGridSemiregular,\\\n",
        "DeviatoricGridSemiregular\n",
        "from mtuq.grid_search import grid_search\n",
        "from mtuq.misfit import Misfit\n",
        "from mtuq.process_data import ProcessData\n",
        "from mtuq.util import fullpath, merge_dicts, save_json\n",
        "from mtuq.util.cap import parse_station_codes, Trapezoid\n",
        "\n",
        "from matplotlib import gridspec\n",
        "\n",
        "path_data=    '/content/mtuq/data/examples/20090407201255351/*.[zrt]'\n",
        "path_weights= '/content/mtuq/data/examples/20090407201255351/weights.dat'\n",
        "event_id=     '20090407201255351'\n",
        "model=        'ak135'\n",
        "\n",
        "station_id_list = parse_station_codes(path_weights)\n",
        "\n",
        "origin = Origin({\n",
        "    'time': '2009-04-07T20:12:55.000000Z',\n",
        "    'latitude': 61.454200744628906,\n",
        "    'longitude': -149.7427978515625,\n",
        "    'depth_in_m': 33033.599853515625,\n",
        "    })\n",
        "\n",
        "data = read(path_data,\n",
        "    event_id=event_id,\n",
        "    station_id_list=station_id_list,\n",
        "    tags=['units:m', 'type:velocity'])\n",
        "\n",
        "data.sort_by_distance()\n",
        "stations = data.get_stations()\n",
        "# # # ... then the interactive map definition\n",
        "def display_event_map():\n",
        "  try:\n",
        "      import folium\n",
        "      from folium import Figure\n",
        "  except ImportError:\n",
        "      %pip install folium\n",
        "      import folium\n",
        "\n",
        "  # Get data for the map\n",
        "  sta_latitudes=[sta['latitude'] for sta in stations]\n",
        "  sta_longitudes=[sta['longitude'] for sta in stations]\n",
        "  sta_names = [sta.id for sta in stations]\n",
        "\n",
        "  # Rest of your code using folium\n",
        "  fig = Figure(width=800, height=600)\n",
        "\n",
        "  m = folium.Map(location=[61.45, -149.74], zoom_start=6)\n",
        "\n",
        "  folium.TileLayer('stamentoner').add_to(m)\n",
        "\n",
        "  # Add a marker for each station\n",
        "  for i in range(len(sta_latitudes)):\n",
        "      folium.Marker(\n",
        "          location=[sta_latitudes[i], sta_longitudes[i]],\n",
        "          icon=folium.DivIcon(\n",
        "              icon_size=(20, 20),\n",
        "              icon_anchor=(0, 0),\n",
        "              html=f'<div style=\"font-size: 12; color:#d35400;\"><b>{sta_names[i]}</b></div><div style=\"transform: rotate(180deg); width: 0; height: 0; border-left: 5px solid transparent; border-right: 5px solid transparent; border-top: 10px solid black;\"></div>',\n",
        "          ),\n",
        "          color='red', prefix='fa'  # Corrected icon\n",
        "      ).add_to(m)\n",
        "\n",
        "  # Add a marker for the event as a yellow star with black outlines\n",
        "  folium.Marker(\n",
        "      location=[origin.latitude, origin.longitude],\n",
        "      icon=folium.DivIcon(\n",
        "          icon_size=(20, 20),\n",
        "          icon_anchor=(0, 0),\n",
        "          # Use fontawesome to get the star icon and color it yellow with black outlines\n",
        "          html='<i class=\"fa-solid fa-star\" style=\"font-size: 14px; color: yellow; -webkit-text-stroke: 2px black;\"></i>',\n",
        "      ),\n",
        "      color='yellow', prefix='fa'\n",
        "  ).add_to(m)\n",
        "\n",
        "  m.add_to(fig)\n",
        "\n",
        "  # Add a marker for Canberra, Australia -- That's where I am at!\n",
        "  for i in np.arange(-5,5+1,1):\n",
        "    folium.Marker(\n",
        "        location=[-35.28, 149.13+i*360],\n",
        "        icon=folium.Icon(color='blue', icon='info-sign'),\n",
        "        tooltip='Canberra'\n",
        "    ).add_to(m)\n",
        "\n",
        "    m.add_to(fig)\n",
        "\n",
        "  return fig\n",
        "\n",
        "# Now we define the grid widgets -- also using some of MTUQ methods and functions\n",
        "from ipywidgets import interactive\n",
        "from IPython.display import display\n",
        "from mtuq.util.math import to_delta_gamma\n",
        "from mtuq.graphics.uq._matplotlib import _hammer_projection, _generate_lune\n",
        "\n",
        "def _add_dc_labels(ax2, ax3, ax4, **kwargs):\n",
        "    kappa_ticks = [0, 45, 90, 135, 180, 225, 270, 315, 360]\n",
        "    kappa_ticklabels = ['0', '', '90', '', '180', '', '270', '', '360']\n",
        "\n",
        "    sigma_ticks = [-90, -67.5, -45, -22.5, 0, 22.5, 45, 67.5, 90]\n",
        "    sigma_ticklabels = ['-90', '', '-45', '', '0', '', '45', '', '90']\n",
        "\n",
        "    h_ticks = [np.cos(np.radians(tick)) for tick in [0, 15, 30, 45, 60, 75, 90]]\n",
        "    h_ticklabels = ['0', '', '30', '', '60', '', '90']\n",
        "\n",
        "    # upper left panel\n",
        "    ax2.set_xlabel('Dip', **kwargs)\n",
        "    ax2.set_xticks(h_ticks)\n",
        "    ax2.set_xticklabels(h_ticklabels)\n",
        "    ax2.set_ylabel('Strike', **kwargs)\n",
        "    ax2.set_yticks(kappa_ticks)\n",
        "    ax2.set_yticklabels(kappa_ticklabels)\n",
        "\n",
        "    # upper right panel\n",
        "    ax3.set_xlabel('Slip', **kwargs)\n",
        "    ax3.set_xticks(sigma_ticks)\n",
        "    ax3.set_xticklabels(sigma_ticklabels)\n",
        "    ax3.set_ylabel('Strike', **kwargs)\n",
        "    ax3.set_yticks(kappa_ticks)\n",
        "    ax3.set_yticklabels(kappa_ticklabels)\n",
        "\n",
        "    # lower right panel\n",
        "    ax4.set_xlabel('Slip', **kwargs)\n",
        "    ax4.set_xticks(sigma_ticks)\n",
        "    ax4.set_xticklabels(sigma_ticklabels)\n",
        "    ax4.set_ylabel('Dip', **kwargs)\n",
        "    ax4.set_yticks(h_ticks)\n",
        "    ax4.set_yticklabels(h_ticklabels)\n",
        "\n",
        "# Triggers when the widget us updated\n",
        "def lune_grid_update(n_points):\n",
        "  fig, ax = _generate_lune()\n",
        "\n",
        "  # Clear existing content of the axes\n",
        "  ax.cla()\n",
        "  _generate_lune(ax=ax) # This is to overlay the lune over the first ax.\n",
        "\n",
        "  grid = FullMomentTensorGridSemiregular(3, n_points)\n",
        "  v, w = grid.coords[1:3]\n",
        "  delta,gamma = to_delta_gamma(v, w)\n",
        "  D,G = np.meshgrid(delta, gamma)\n",
        "  x, y = _hammer_projection(G, D)\n",
        "  # Plot the new points\n",
        "  ax.scatter(x, y, s=0.5, c='black', zorder=100)\n",
        "  ax.set_xlim(-30,30)\n",
        "  ax.set_ylim(-90,90)\n",
        "\n",
        "  # Display the updated plot\n",
        "  plt.show()\n",
        "\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display, clear_output\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import gridspec\n",
        "import numpy as np\n",
        "# # # Logic that handles updates\n",
        "def grid_update(n_points, gridtype):\n",
        "    print(f\"Grid type: {gridtype}\")  # Just to check which grid type is selected\n",
        "    fig = plt.figure(figsize=(8.5, 6))\n",
        "    gs = gridspec.GridSpec(2, 3, height_ratios=[1, 1])\n",
        "    ax1 = fig.add_subplot(gs[:, 0])\n",
        "    # Dummy function call (replace with your own)\n",
        "    _, ax1 = _generate_lune(ax1)\n",
        "    ax1.set_axis_off()\n",
        "\n",
        "    ax2 = fig.add_subplot(gs[0, 1])\n",
        "    ax3 = fig.add_subplot(gs[0, 2])\n",
        "    ax4 = fig.add_subplot(gs[1, 2])\n",
        "\n",
        "    ax1.cla()\n",
        "    ax2.cla()\n",
        "    ax3.cla()\n",
        "    ax4.cla()\n",
        "\n",
        "    _add_dc_labels(ax2, ax3, ax4)\n",
        "\n",
        "    # Some variable init (to get grid size)\n",
        "    grid = DoubleCoupleGridRegular(1, n_points)\n",
        "    if gridtype == 'Double-couple':\n",
        "      grid = DoubleCoupleGridRegular(1, n_points)\n",
        "    elif gridtype == 'Deviatoric':\n",
        "      grid = DeviatoricGridSemiregular(1, n_points)\n",
        "    elif gridtype == 'Full MT':\n",
        "      grid = FullMomentTensorGridSemiregular(1, n_points)\n",
        "\n",
        "    # Lune part\n",
        "    v, w = grid.coords[1:3]\n",
        "    delta,gamma = to_delta_gamma(v, w)\n",
        "    D,G = np.meshgrid(delta, gamma)\n",
        "    x, y = _hammer_projection(G, D)\n",
        "    ax1.scatter(x, y, s=3, c='black', zorder=100)\n",
        "    ax1.set_xlim(-30,30)\n",
        "    ax1.set_xlabel('Lune longitude')\n",
        "    ax1.set_ylim(-90,90)\n",
        "    ax1.set_ylabel('Lune colatitude')\n",
        "\n",
        "    # DC part\n",
        "    strike = grid.coords[3]\n",
        "    dip = grid.coords[5]\n",
        "    slip = grid.coords[4]\n",
        "    # upper left panel\n",
        "    ax2.scatter(*np.meshgrid(dip, strike), s=3, c='black', zorder=100)\n",
        "    ax2.set_xlim(0, 1)\n",
        "    ax2.set_ylim(0, 360)\n",
        "    # upper right panel\n",
        "    ax3.scatter(*np.meshgrid(slip, strike), s=3, c='black', zorder=100)\n",
        "    ax3.set_xlim(-90, 90)\n",
        "    ax3.set_ylim(0, 360)\n",
        "    # lower right panel\n",
        "    ax4.scatter(*np.meshgrid(slip, dip), s=3, c='black', zorder=100)\n",
        "    ax4.set_xlim(-90, 90)\n",
        "    ax4.set_ylim(0, 1)\n",
        "\n",
        "    fig.tight_layout()\n",
        "\n",
        "# # # Logic when moving the slider\n",
        "def on_slider_change(change):\n",
        "    n_points = change['new']\n",
        "    gridtype = dropdown.value\n",
        "\n",
        "    grid = DoubleCoupleGridRegular(1, n_points)\n",
        "    if gridtype == 'Double-couple':\n",
        "      grid = DoubleCoupleGridRegular(1, n_points)\n",
        "    elif gridtype == 'Deviatoric':\n",
        "      grid = DeviatoricGridSemiregular(1, n_points)\n",
        "    elif gridtype == 'Full MT':\n",
        "      grid = FullMomentTensorGridSemiregular(1, n_points)\n",
        "\n",
        "    total_points = grid.size\n",
        "    label.value = f'Total grid points: {total_points:,}'\n",
        "    clear_output(wait=True)\n",
        "    display(dropdown, slider, label)\n",
        "    grid_update(n_points, gridtype)\n",
        "# # # Logic when changing the grid type\n",
        "def on_dropdown_change(change):\n",
        "    gridtype = change['new']\n",
        "    n_points = slider.value\n",
        "\n",
        "    grid = DoubleCoupleGridRegular(1, n_points)\n",
        "    if gridtype == 'Double-couple':\n",
        "      grid = DoubleCoupleGridRegular(1, n_points)\n",
        "    elif gridtype == 'Deviatoric':\n",
        "      grid = DeviatoricGridSemiregular(1, n_points)\n",
        "    elif gridtype == 'Full MT':\n",
        "      grid = FullMomentTensorGridSemiregular(1, n_points)\n",
        "\n",
        "    total_points = grid.size\n",
        "    label.value = f'Total grid points: {total_points:,}'\n",
        "    clear_output(wait=True)\n",
        "    display(dropdown, slider, label)\n",
        "    grid_update(n_points, gridtype)\n",
        "\n",
        "# # # Reducing the search space size of the full moment tensor examples # # #\n",
        "file_path = '/content/mtuq/examples/GridSearch.FullMomentTensor.py'\n",
        "\n",
        "with open(file_path, 'r') as file:\n",
        "    lines = file.readlines()\n",
        "# Change the grid size by fixing the magnitude.\n",
        "for i, line in enumerate(lines):\n",
        "    if \"magnitudes=[4.4, 4.5, 4.6, 4.7]\" in line:\n",
        "        lines[i] = line.replace(\"magnitudes=[4.4, 4.5, 4.6, 4.7]\", \"magnitudes=[4.5]\")\n",
        "\n",
        "with open(file_path, 'w') as file:\n",
        "    file.writelines(lines)\n",
        "!ln -s /content/mtuq/data /usr/local/lib/python3.10/dist-packages/\n",
        "\n",
        "# # # Caching Green's functions for the 2009 example # # #\n",
        "if len(os.listdir('/content/mtuq/data/greens_tensor/syngine/cache')) <= 1:\n",
        "  key = np.random.randint(0,2)\n",
        "  if key == 0:\n",
        "    !gdown https://drive.google.com/file/d/10BHaB7sIq2k2pX4NtlI3lmIoT_9YBP2F/view?usp=sharing --fuzzy\n",
        "  elif key == 1:\n",
        "    !gdown https://drive.google.com/file/d/15XESyItZTxNhkO7n-C-CaTHEZKpYYMaa/view?usp=sharing --fuzzy\n",
        "  !mv cache.zip /content/mtuq/data/greens_tensor/syngine/ -f\n",
        "  !unzip -o /content/mtuq/data/greens_tensor/syngine/cache.zip -d /content/mtuq/data/greens_tensor/syngine/\n",
        "  !rm -fr /content/mtuq/data/greens_tensor/syngine/__MACOSX\n",
        "\n",
        "\n",
        "# # # Custom waveform plotting function (Courtesy of Aakash Gupta)\n",
        "def plot_seismic_waves(station_num, component, data, data_bw, data_sw, origin_time, t1=-50, t2=150):\n",
        "    \"\"\"\n",
        "    Plots seismic waves for a given station and component.\n",
        "\n",
        "    Parameters:\n",
        "    station_num (int): Integer between 0 and 19 representing the station number.\n",
        "    component (str): 'Z', 'R', or 'T' representing the component.\n",
        "    data (list): List containing raw seismic data.\n",
        "    data_bw (list): List containing body wave data.\n",
        "    data_sw (list): List containing surface wave data.\n",
        "    origin_time (UTCDateTime object): Origintime of the event.\n",
        "    t1 (int): Start time in seconds after data origintime. Default is -50.\n",
        "    t2 (int): End time in seconds after data origintime. Default is 150.\n",
        "    \"\"\"\n",
        "    def get_trace_data(st, ref_time):\n",
        "        if len(st) > 0:\n",
        "            tr = st[0]\n",
        "            return tr.times() + (tr.stats.starttime - ref_time), tr.data\n",
        "        return None, None\n",
        "\n",
        "    st1 = data[station_num].select(component=component)\n",
        "    st2 = data_bw[station_num].select(component=component)\n",
        "    st3 = data_sw[station_num].select(component=component)\n",
        "\n",
        "    tr1 = st1[0]\n",
        "    x = [tr1.times()]\n",
        "    y = [tr1.data]\n",
        "    wave_type = [\"raw wave\"]\n",
        "\n",
        "    x2, y2 = get_trace_data(st2, tr1.stats.starttime)\n",
        "    if x2 is not None and y2 is not None:\n",
        "        x.append(x2)\n",
        "        y.append(y2)\n",
        "        wave_type.append(\"body wave\")\n",
        "    else:\n",
        "        print(\"No body waves to be displayed: weight is 0\")\n",
        "\n",
        "    x3, y3 = get_trace_data(st3, tr1.stats.starttime)\n",
        "    if x3 is not None and y3 is not None:\n",
        "        x.append(x3)\n",
        "        y.append(y3)\n",
        "        wave_type.append(\"surface wave\")\n",
        "    else:\n",
        "        print(\"No surface waves to be displayed: weight is 0\")\n",
        "\n",
        "    t_shift = origin_time - tr1.stats.starttime\n",
        "\n",
        "    fig, axs = plt.subplots(len(x), 1, sharex=True, figsize=(8, 8))\n",
        "    if len(x) == 1:\n",
        "        axs = [axs]  # Make sure axs is a list even if there's only one subplot\n",
        "    axs[0].set_title(f\"Station's ID: {tr1.id},    origin_time: {origin_time}\")\n",
        "\n",
        "    for i, ax in enumerate(axs):\n",
        "        ax.plot(x[i] - t_shift, y[i], label=wave_type[i])\n",
        "        ax.axhline(y=0, color='k', linestyle='--', alpha=0.3)\n",
        "        ax.set_xlim([t1, t2])\n",
        "        y_amp = max(abs(y[i]))\n",
        "        ax.set_ylim([-1.1 * y_amp, 1.1 * y_amp])\n",
        "        ax.xaxis.set_tick_params(which='both', labelbottom=True)\n",
        "        ax.legend()\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "# # # Initializing the working directory\n",
        "!rm -fr /content/sample_data\n",
        "!mkdir /content/workdir/\n",
        "!mkdir /content/workdir/2009_04_07/\n",
        "%cd /content/workdir/2009_04_07/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_GGzfbZXncoj"
      },
      "source": [
        "### 1.3.0 MTUQ built-in example: 4.5M<sub>w</sub> earthquake near Anchorage, AK\n",
        "First, let us have a look at the first example event. We're taking advantage of being in an interactive environment to display a map of the event and stations. You can have a look at the [USGS page for this event](https://earthquake.usgs.gov/earthquakes/eventpage/ak0094gr40v3/executive), which includes their catalog information for the origin time and location, along with their fault-plane solution/moment tensor.\n",
        "\n",
        "We will work with 20 stations, with data pulled from the AK, AT, and YV networks."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QpZdF7limu7n"
      },
      "outputs": [],
      "source": [
        "# A simple source - receiver map (not part of the standard MTUQ)\n",
        "display_event_map()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PPF0zkVMn5Dz"
      },
      "source": [
        "This is a reasonably well-constrained event with a small azimuthal gap and a good number of nearby stations. So now let's get into the default example script:\n",
        "`mtuq/examples/examples/SerialGridSearch.DoubleCouple.py`\n",
        "This will take us through setting up our first grid search.\n",
        "\n",
        "### 1.4.0 Importing the necessary classes and functions from the MTUQ package\n",
        "The first step of any MTUQ script that you will find in the examples folder will contain imports to several key classes and functions from MTUQ. While some are standard and expected to be present in most scripts, others are specific to the type of inversion you are performing (such as the type of `Grid` object constructor you will be using). In the following example, you will see that we will be using a regular grid spanning the double-couple source domain with: `DoubleCoupleGridRegular`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ECAtRlwVnJp-"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "\n",
        "from mtuq import read, open_db, download_greens_tensors\n",
        "from mtuq.event import Origin\n",
        "from mtuq.graphics import plot_data_greens2, plot_beachball, plot_misfit_dc\n",
        "from mtuq.grid import DoubleCoupleGridRegular, FullMomentTensorGridSemiregular\n",
        "from mtuq.grid_search import grid_search\n",
        "from mtuq.misfit import Misfit\n",
        "from mtuq.process_data import ProcessData\n",
        "from mtuq.util import fullpath, merge_dicts, save_json\n",
        "from mtuq.util.cap import parse_station_codes, Trapezoid"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pgL3kkmydeIr"
      },
      "source": [
        "Following the module and functions imports, we provide a path to a data directory ('path_data') containing waveforms stored as `.sac` files and a weight file (`path_weight`), which is used in MTUQ to fine-tune an inversion (by adjusting each trace weight or using hand-picked arrival times, for instance)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E0JhojrHdjLo"
      },
      "outputs": [],
      "source": [
        "path_data=    '/content/mtuq/data/examples/20090407201255351/*.[zrt]'\n",
        "path_weights= '/content/mtuq/data/examples/20090407201255351/weights.dat'\n",
        "event_id=     '20090407201255351'\n",
        "model=        'ak135'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QBZ5-0sBqKZ9"
      },
      "source": [
        "For this example, we will use it as it is; here is what the provided `weights.dat` file looks like:\n",
        "\n",
        "||Station ID|Dist (km)|P-vertical|P-radial|S\\_vertical|S\\_radial|S\\_transverse|P\\_otime|Legacy|S\\_otime|Legacy`|Rayleigh\\_tshift|\n",
        "|---|---|---|---|---|---|---|---|---|---|---|---|---|\n",
        "||20090407201255351\\.YV\\.BIGB\\.\\.BH|16|1|1|1|1|0|0\\.00|0\\.00|0|0|0|\n",
        "||20090407201255351\\.YV\\.ALPI\\.\\.BH|25|0|0|0|0|0|0\\.00|0\\.00|0|0|0|\n",
        "||20090407201255351\\.AT\\.PMR\\.\\.BH|36|1|1|1|1|1|0\\.00|0\\.00|0|0|0|\n",
        "||20090407201255351\\.AK\\.RC01\\.\\.BH|40|0|0|0|0|0|0\\.00|0\\.00|0|0|0|\n",
        "||20090407201255351\\.YV\\.KASH\\.\\.BH|49|0|0|1|1|1|0\\.00|0\\.00|0|0|0|\n",
        "||20090407201255351\\.YV\\.HOPE\\.\\.BH|65|0|0|0|0|0|0\\.00|0\\.00|0|0|0|\n",
        "||20090407201255351\\.YV\\.TUPA\\.\\.BH|78|1|1|0|0|0|0\\.00|0\\.00|0|0|0|\n",
        "||20090407201255351\\.AK\\.SAW\\.\\.BH|85|0|0|0|0|0|0\\.00|0\\.00|0|0|0|\n",
        "||20090407201255351\\.YV\\.LSUM\\.\\.BH|88|1|1|1|1|1|0\\.00|0\\.00|0|0|0|\n",
        "||20090407201255351\\.YV\\.MPEN\\.\\.BH|89|0|1|0|1|1|0\\.00|0\\.00|0|0|0|\n",
        "||20090407201255351\\.YV\\.DEVL\\.\\.BH|101|1|1|1|1|1|0\\.00|0\\.00|0|0|0|\n",
        "||20090407201255351\\.YV\\.BLAK\\.\\.BH|104|1|1|1|1|1|0\\.00|0\\.00|0|0|0|\n",
        "||20090407201255351\\.YV\\.RUSS\\.\\.BH|109|0|0|0|0|0|0\\.00|0\\.00|0|0|0|\n",
        "||20090407201255351\\.YV\\.LSKI\\.\\.BH|115|1|1|0|0|0|0\\.00|0\\.00|0|0|0|\n",
        "||20090407201255351\\.YV\\.NSKI\\.\\.BH|121|0|0|1|1|1|0\\.00|0\\.00|0|0|0|\n",
        "||20090407201255351\\.YV\\.AVAL\\.\\.BH|122|1|1|1|1|1|0\\.00|0\\.00|0|0|0|\n",
        "||20090407201255351\\.YV\\.PERI\\.\\.BH|127|1|1|1|1|1|0\\.00|0\\.00|0|0|0|\n",
        "||20090407201255351\\.YV\\.SOLD\\.\\.BH|132|0|0|0|1|1|0\\.00|0\\.00|0|0|0|\n",
        "||20090407201255351\\.AV\\.SPBG\\.\\.BH|142|0|0|0|0|0|0\\.00|0\\.00|0|0|0|\n",
        "||20090407201255351\\.AK\\.SWD\\.\\.BH|150|1|1|1|1|1|0\\.00|0\\.00|0|0|0|\n",
        "||20090407201255351\\.YV\\.HEAD\\.\\.BH|162|1|1|1|1|1|0\\.00|0\\.00|0|0|0|\n",
        "||20090407201255351\\.AK\\.DIV\\.\\.BH|216|1|1|1|1|1|0\\.00|0\\.00|0|0|0|\n",
        "||20090407201255351\\.AK\\.TRF\\.\\.BH|225|1|1|0|0|0|0\\.00|0\\.00|0|0|0|\n",
        "||20090407201255351\\.AK\\.EYAK\\.\\.BH|239|1|1|1|1|1|0\\.00|0\\.00|0|0|0|\n",
        "||20090407201255351\\.AK\\.PAX\\.\\.BH|280|0|0|1|1|1|0\\.00|0\\.00|0|0|0|\n",
        "||20090407201255351\\.AK\\.BMR\\.\\.BH|282|0|0|1|1|1|0\\.00|0\\.00|0|0|0|\n",
        "\n",
        "<br/><br/>\n",
        "The 3rd to 7th columns define the weight attributed to different waveforms, specifically the Z-R body waves and Z-R-T surface waves. These waveforms can, and often will, influence the outcome of our inversions. There are no upper bounds for the weights: you can treat the values as percentages or define an arbitrary weighting system of your own with values greater than 1.\n",
        "\n",
        "The previous code cell also defines an `event_id` that we can use to customize the output files dynamically and the name of the `model` from which we will download Green's Function databases. If you don't have a local Green's function database available locally, you have the option to download the Green's function for your source-receiver pairs dynamically from [syngine](http://ds.iris.edu/ds/products/syngine/), with various options for the *ak135f*, *prem* and *iasp91* models (more details available on the syngine webpage).\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ICiSed36TMh0"
      },
      "source": [
        "### 1.5.0 Data processing\n",
        "Data processing plays an important role in any waveform-based inversion as it will directly influence the content of the seismic traces that we will compare. In MTUQ, the data processing stage is responsible for\n",
        "* Filtering\n",
        "* Windowing\n",
        "* Padding\n",
        "* Amplitude correction\n",
        "* Static time-shift correction (optional - defined in weight file)\n",
        "\n",
        "As per the MTUQ philosophy, everything is modular, and it is possible to process your data in many different ways. Here, we show the \"standard\" approach, where body and surface waves are treated separately.\n",
        "\n",
        "You could potentially define a pre-processing function for each of the 5 data groups mentioned in the weight file or combining different datasets calling for tailored filtering scenarios (strong motion and broadband data for instance)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FH3DcS_blzg2"
      },
      "outputs": [],
      "source": [
        "# Defining the Body-wave specific data processing\n",
        "process_bw = ProcessData(\n",
        "    filter_type='Bandpass',\n",
        "    freq_min= 0.1, # This is in Hertz = 1/10s\n",
        "    freq_max= 0.333, # = 1/3s\n",
        "    pick_type='taup',\n",
        "    taup_model=model,\n",
        "    window_type='body_wave',\n",
        "    window_length=15.,\n",
        "    capuaf_file=path_weights,\n",
        "    )\n",
        "# Defining the Surface-wave specific data processing\n",
        "process_sw = ProcessData(\n",
        "    filter_type='Bandpass',\n",
        "    freq_min=0.025, # This is in Hertz = 1/40s\n",
        "    freq_max=0.0625, # = 1/16s\n",
        "    pick_type='taup',\n",
        "    taup_model=model,\n",
        "    window_type='surface_wave',\n",
        "    window_length=150.,\n",
        "    capuaf_file=path_weights,\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QJkX4NACfsFy"
      },
      "source": [
        "### 1.6.0 Defining the misfit functions\n",
        "`MTUQ` currently supports several waveform-based misfit functions. Recalling that a given discrete waveform residual $r$ is expressed as:\n",
        "\n",
        "$\\mathbf{r} = \\mathbf{Gm} - \\mathbf{d}$,\n",
        "\n",
        "with $\\mathbf{G}$ being the set of discrete Green's function for $i$ source-receiver pairs, $\\mathbf{m}$ the vector source term (6 independent moment tensor components / 3 components point force -- hence $\\mathbf{Gm}$ expresses the set of $i$ synthetic waveform data) and $\\mathbf{d}$ the $i$ observed data, `MTUQ` can consider the following misfit functions:\n",
        "\n",
        "* L1 misfit: $\\sum_{i} \\lvert{r_i}\\rvert$\n",
        "* L2 misfit: $\\sum_{i} {r_i^2}$\n",
        "* *'Hybrid'* misfit: $\\left(\\sum_{i} {r_i^2}\\right)^{1/2}$\n",
        "\n",
        "The `L2` (which is really a squared version of the canonical Euclidean distance) and `hybrid` modes benefit from a particular treatment, as they have been implemented in highly optimized C-code. We do not recommend using the `L1` norm on larger grids as it is computationally inefficient.\n",
        "\n",
        "In the next cell, we allocate two misfit objects, both based on squared residual distances (`L2` mode).\n",
        "\n",
        "The body waves are organized in a single group (`ZR`), which means an identical time shift will be imposed. The synthetics will be compared with the observed data using a sliding cross-correlation window of $\\pm 2~s$, i.e., the time-shift parameters are here to accommodate the expected time differences that the velocity model does not explain.\n",
        "\n",
        "The surface waves are partitioned in two distinct time-shift groups:\n",
        "`ZR` and `T` (representing the Rayleigh and Love waves, respectively). We group them by *wave-types*, as Rayleigh and Love waves don't have the same theoretical phase velocity: we can't expect them to have the same arrival time."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zutXvJMMl3j9"
      },
      "outputs": [],
      "source": [
        "# Body wave misfit\n",
        "misfit_bw = Misfit(\n",
        "    norm='L2',\n",
        "    time_shift_min=-2., # Feel free to play with this so we can check\n",
        "    time_shift_max=+2., # how different your result will be!\n",
        "    time_shift_groups=['ZR'],\n",
        "    )\n",
        "\n",
        "# Surface wave misfit\n",
        "misfit_sw = Misfit(\n",
        "    norm='L2',\n",
        "    time_shift_min=-10., # You can change this ...\n",
        "    time_shift_max=+10., # ... and this too\n",
        "    time_shift_groups=['ZR','T'],\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AVx7q0YSfuOx"
      },
      "source": [
        "### 1.7.0 Choosing a grid\n",
        "In `MTUQ` standard mode, we measure the waveform misfit along a pre-defined grid of sources. Our goal is to explore the parameter-space spanning as many source orientations, type, magnitude, and potentially location.\n",
        "\n",
        "For this, we use a pre-defined grid object that loads all the coordinates we are going to explore in the moment tensor space. We will begin by searching only double couple solution:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lf9PTJhzocZA"
      },
      "outputs": [],
      "source": [
        "# Initializing a grid spanning the double couple space, for a single magnitude\n",
        "grid = DoubleCoupleGridRegular(\n",
        "    npts_per_axis=40,\n",
        "    magnitudes=[4.5])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BAZHKDHY1Pe_"
      },
      "source": [
        "Let's have a look at how the number of points per axes influences the grid search density.\n",
        "The grid initialized above is a double couple grid, which means we will only search through the Strike, Dip, and Slip values (this defines the moment tensor \"orientation\").\n",
        "\n",
        "Hence, with 40 points per axes, we are looking at $40^3 = 64,000$ grid points.\n",
        "\n",
        "There are three main regular / semi-regular grids for moment-tensors in `MTUQ`:\n",
        "* Double-couple\n",
        "* Deviatoric\n",
        "* Full moment tensor\n",
        "\n",
        "Let's see what they are about and how the choice of grid type and number of points per axes influences the size of search space they are associated with."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "q9Gr9coT1PCZ"
      },
      "outputs": [],
      "source": [
        "#@title 1.7.1 Visualizing grid type and sizes\n",
        "# Let's initialize a grid-visualization widget\n",
        "slider = widgets.IntSlider(value=3, min=3, max=40, step=1, description='npts_per_axes:', continuous_update=False)\n",
        "dropdown = widgets.Dropdown(options=['Double–Couple', 'Deviatoric', 'Full MT'], value='Double–Couple', description='Grid Type:')\n",
        "label = widgets.Label()\n",
        "# Initialize display by simulating a change\n",
        "on_slider_change({'new': slider.value})\n",
        "# Activate the widget\n",
        "slider.observe(on_slider_change, names='value')\n",
        "dropdown.observe(on_dropdown_change, names='value')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fW8Bvf1ybNP1"
      },
      "source": [
        "This goes to show how the choice of grid will affect the resolution of your solution, but also your computational load, as the full moment tensor grid is more than 2~3 orders of magnitude greater than the double-couple grid. For each M<sub>w</sub> or origin location (depth), we add new layers to the grid, which can quickly increase the size of the search domain."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "knfftMKDUXKD"
      },
      "source": [
        "### 1.8.0 Event's origin\n",
        "Now let's check how we define the origin time of our event. The Origin object is a pretty straightforward class that encodes the temporal and spatial information of our source.\n",
        "\n",
        "Typically, this would come from another analysis you've made to locate the source, or from an existing catalog you want to re-evaluate."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pU1J-x9BmAEx"
      },
      "outputs": [],
      "source": [
        "origin = Origin({\n",
        "    'time': '2009-04-07T20:12:55.000000Z',\n",
        "    'latitude': 61.454200744628906,\n",
        "    'longitude': -149.7427978515625,\n",
        "    'depth_in_m': 33033.599853515625,\n",
        "    })"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NOUMOkGpez_w"
      },
      "source": [
        "### 1.9.0 Reading the data\n",
        "We will now import the data from the path we provided a couple of cells above. First, we check for the weight files for all 0-weight stations that shouldn't be loaded.\n",
        "\n",
        "Then, all the data we wish to use are loaded from the `.sac` files in the folder `path_data`. Here, the `.sac` files contain velocity recordings in m/s (which is also the default unit provided by the companion software, `PySEP`, which we use to download and pre-process data). The unfiltered data are stored as a list of `obspy.Stream` objects.\n",
        "\n",
        "The `stations` list contains a helpful list of all station attributes (ID, Network, location, azimuth/back azimuth with respect to the source, distance to the source, etc.) obtained from the sac header.\n",
        "\n",
        "Finally, we \"map\" the two processing functions to the list of streams in `data` to generate the P-wave and surface-wave data (windowed and filtered)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AqPyyHjKmEOo"
      },
      "outputs": [],
      "source": [
        "print('Reading data...\\n')\n",
        "station_id_list = parse_station_codes(path_weights)\n",
        "data = read(path_data, format='sac',\n",
        "    event_id=event_id,\n",
        "    station_id_list=station_id_list,\n",
        "    tags=['units:m', 'type:velocity'])\n",
        "\n",
        "\n",
        "data.sort_by_distance()\n",
        "stations = data.get_stations()\n",
        "\n",
        "\n",
        "print('Processing data...\\n')\n",
        "data_bw = data.map(process_bw)\n",
        "data_sw = data.map(process_sw)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C7nbW7lwu0Wx"
      },
      "source": [
        "Let's have a look at some of the data to see how `process_bw` and `process_sw` change the original data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1SHNS2015JiM"
      },
      "outputs": [],
      "source": [
        "station_num = 4 # Integer between 0 and 19\n",
        "component = \"T\" # 'Z' 'R' or 'T'\n",
        "# Call a custom plotting function\n",
        "plot_seismic_waves(station_num, component, data, data_bw, data_sw, origin[\"time\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-gRi4UwMUdu5"
      },
      "source": [
        "### 1.10.0 Green's functions databases\n",
        "In order to speed up computation, `MTUQ` relies on pre-computed Green's functions databases. These databases contain the individual Green's functions for each source-receiver pairs in our problem set. The Green's function database is a collection of synthetic impulse responses for a set of elemental sources, from which we can generate our synthetic waveforms $\\mathbf{d_{syn}}$ efficiently with a simple linear combination:\n",
        "\n",
        "$\\mathbf{d_{syn}} = \\mathbf{Gm}$\n",
        "\n",
        "\n",
        "\n",
        "Currently, MTUQ offers direct support to several numerical modeling codes, with dedicated clients to import Green's functions from local databases computed with:\n",
        "- 1D codes:\n",
        "  - [Axisem](https://github.com/geodynamics/axisem)\n",
        "  - [FK](https://www.eas.slu.edu/People/LZhu/home.html)\n",
        "- 3D codes:\n",
        "  - [SPECFEM3D_Cartesian](https://github.com/SPECFEM/specfem3d)\n",
        "  - [SPECFEM3D_Globe](https://github.com/SPECFEM/specfem3d_globe)\n",
        "  - [SEISGEN](https://github.com/Liang-Ding/seisgen)\n",
        "\n",
        "When no Green's functions are available locally, MTUQ has the option to fetch them directly from [syngine](http://ds.iris.edu/ds/products/syngine/).\n",
        "\n",
        "To speed up the process for the workshop, an archive with pre-downloaded syngine Green's functions is already loaded it in the `MTUQ` cache folder."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5JXdWMe0mIPb"
      },
      "outputs": [],
      "source": [
        "print('Defining a trapezoid source-time-function...\\n')\n",
        "wavelet = Trapezoid(\n",
        "    magnitude=4.5)\n",
        "\n",
        "print('Reading Greens functions...\\n')\n",
        "# This line would normally fetch Green's function one at a time from syngine, but\n",
        "# we're cheating here for the sake of time: the syngine GF's are already cached\n",
        "# in the /content/mtuq/data/greens_tensor/syngine/cache/ folder.\n",
        "greens = download_greens_tensors(stations, origin, model)\n",
        "\n",
        "print('Processing Greens functions...\\n')\n",
        "greens.convolve(wavelet)\n",
        "greens_bw = greens.map(process_bw)\n",
        "greens_sw = greens.map(process_sw)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JpKr3MGCUrey"
      },
      "source": [
        "### 1.11.0 Grid search and results\n",
        "\n",
        "Now that the following is ready:\n",
        "* Defining the grid and misfit,\n",
        "* Data import,\n",
        "* Data-processing,\n",
        "* Importing and processing Green's functions,\n",
        "\n",
        "we can move on to the actual grid search. To do so, we will independently run the `grid_search` function  that takes the following as arguments:\n",
        "* A pair of processed data-green's functions lists,\n",
        "* the corresponding misfit you wish to evaluate (allowable time shift, misfit type, time-shift groups),\n",
        "* an origin or a list of origins (if searching for the best depth),\n",
        "* and the grid, which defines the coordinates (sources) that are going to be evaluated\n",
        "\n",
        "The grid-search function rapidly generates synthetics for each grid point, runs the cross-correlation, and returns the misfit value for the aligned obs-syn pair for each station and time-shift group.\n",
        "\n",
        "We end up with a large multidimensional array, with a single value for each coordinate for each `grid_search` function call (here, the P-waves misfit -- `misfit_bw`, and the surface waves misfit -- `misfit_sw`).\n",
        "\n",
        "In MTUQ, we do not provide a fixed misfit formula to combine misfit contributions. Instead, you have the flexibility to combine all misfit contributions as you see fit. In this example, we sum both misfit contributions.\n",
        "\n",
        "(This grid-search will take **about ~40s**)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h6C9dXXqjmy9"
      },
      "outputs": [],
      "source": [
        "#\n",
        "# The main computational work starts now\n",
        "#\n",
        "\n",
        "print('Evaluating body wave misfit...\\n')\n",
        "results_bw = grid_search(data_bw, greens_bw, misfit_bw, origin, grid)\n",
        "\n",
        "print('Evaluating surface wave misfit...\\n')\n",
        "results_sw = grid_search(data_sw, greens_sw, misfit_sw, origin, grid)\n",
        "\n",
        "results = results_bw + results_sw"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YbZLuxOyjt-A"
      },
      "outputs": [],
      "source": [
        "#\n",
        "# Collect information about best-fitting source\n",
        "#\n",
        "\n",
        "# index of best-fitting moment tensor\n",
        "idx = results.source_idxmin()\n",
        "\n",
        "# MomentTensor object\n",
        "best_mt = grid.get(idx)\n",
        "\n",
        "# dictionary of lune parameters\n",
        "lune_dict = grid.get_dict(idx)\n",
        "\n",
        "# dictionary of Mij parameters\n",
        "mt_dict = best_mt.as_dict()\n",
        "\n",
        "# dictionary containing recap info\n",
        "merged_dict = merge_dicts(\n",
        "    mt_dict, lune_dict, {'M0': best_mt.moment()},\n",
        "    {'Mw': best_mt.magnitude()}, origin)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GTW1_Ra2yCoO"
      },
      "source": [
        "Now let's print the parameters of the best fitting source and run through them.\n",
        "\n",
        "Saving the dictionaries containing all the source parameters as a `.json` file is a convenient to save and share your results, or pass it to other codes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HXzss9Pex_BQ"
      },
      "outputs": [],
      "source": [
        "print('Best-fitting source parameters:')\n",
        "for key, val in merged_dict.items():\n",
        "  print(f'{key}: {val}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ro2AlQvYk3hO"
      },
      "source": [
        "We can now generate a few figures to visualize the results. Here is a subset of the availalbe plotting functions in `MTUQ`:\n",
        "* Waveform comparison plot.\n",
        "* The moment tensor solution with all station piercing points.\n",
        "* A misfit map (here for Double-Couple solutions).\n",
        "\n",
        "We are currently working from the `/content/workdir/2009_04_07` directory. You can check the data on the left."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ipERgaCnjzoP"
      },
      "outputs": [],
      "source": [
        "print('Generating figures...\\n')\n",
        "\n",
        "plot_data_greens2(event_id+'DC_waveforms.png',\n",
        "    data_bw, data_sw, greens_bw, greens_sw, process_bw, process_sw,\n",
        "    misfit_bw, misfit_sw, stations, origin, best_mt, lune_dict)\n",
        "\n",
        "\n",
        "plot_beachball(event_id+'DC_beachball.png',\n",
        "    best_mt, stations, origin)\n",
        "\n",
        "\n",
        "plot_misfit_dc(event_id+'DC_misfit.png', results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wuQOpNPXleyX"
      },
      "source": [
        "Or we can display them all at once."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9ktVCug-qrPK"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import Image, display\n",
        "\n",
        "image_paths = [\n",
        "    '/content/workdir/2009_04_07/20090407201255351DC_beachball.png',\n",
        "    '/content/workdir/2009_04_07/20090407201255351DC_misfit.png',\n",
        "    '/content/workdir/2009_04_07/20090407201255351DC_waveforms.png'\n",
        "]\n",
        "\n",
        "fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
        "for ax, img_path in zip(axes, image_paths):\n",
        "    ax.imshow(plt.imread(img_path))\n",
        "    ax.axis('off')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gaddPGiullKs"
      },
      "source": [
        "Here is how the misfit figure is structured:\n",
        "\n",
        "<figure>\n",
        "<center>\n",
        "<img src=\"https://drive.google.com/uc?id=1aGRHUAp7cGmSx_4twAUOx3qnFodaOwzm\" width=\"300\" alt=\"Representation of the double couple on a fault\">\n",
        "<figcaption>3x3x3 double-couple grid misfit example. The Strike and Dip map is an aggregate of the best misfit along the slip axis.</figcaption>\n",
        "</center>\n",
        "</figure>\n",
        "\n",
        "Now that we have finished working with the results visualization, we can save the output files (json file, and a `NetCDF` file containing all misfit values with their associate coordinates. This step is optional, but can be time saving if you wish to re-process your solution, re-generate figures, etc, as you won't have to go through the grid-search again."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P0a1rjV9j3xn"
      },
      "outputs": [],
      "source": [
        "print('Saving results...\\n')\n",
        "\n",
        "# save best-fitting source\n",
        "save_json(event_id+'DC_solution.json', merged_dict)\n",
        "\n",
        "\n",
        "# save misfit surface\n",
        "results.save(event_id+'DC_misfit.nc')\n",
        "\n",
        "\n",
        "print('\\nFinished\\n')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that we've tried the simplest source type, we can rerun the inversion and change the grid type.\n",
        "\n",
        "In the next cell, we'll make the necessary changes to run a deviatoric moment tensor inversion. Because the grid is slightly larger, you can expect it to run for about **~1min20**."
      ],
      "metadata": {
        "id": "LXN3I2qKBSlm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from mtuq.grid import DeviatoricGridSemiregular\n",
        "from mtuq.graphics import plot_misfit_lune\n",
        "\n",
        "# Remember that all we have done in the previous cells stays in memory\n",
        "\n",
        "grid_dev = DeviatoricGridSemiregular(magnitudes = [4.5], npts_per_axis = 20)\n",
        "\n",
        "results_bw_dev = grid_search(data_bw, greens_bw, misfit_bw, origin, grid_dev)\n",
        "results_sw_dev = grid_search(data_sw, greens_sw, misfit_sw, origin, grid_dev)\n"
      ],
      "metadata": {
        "id": "le8thQ63BjPW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Then, with the new results, we are free to combine them to compute the overall misfit on the grid.\n",
        "\n",
        "We will play with these values a bit to check:\n",
        "* What happens when we use body-waves only?\n",
        "* What happens when we use surface-waves only?\n",
        "* Which part of the dataset drives the results?\n",
        "* What can / should we do about it?\n",
        "* Try to generate figures for a bad solution by changing the results combination.\n",
        "\n",
        "You can check the results in /content/workdir/2009_04_07\n"
      ],
      "metadata": {
        "id": "49W9i5ElF-Tj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/workdir/2009_04_07/\n",
        "\n",
        "results_dev = results_bw_dev + results_sw_dev\n",
        "\n",
        "# index of best-fitting moment tensor\n",
        "idx = results_dev.source_idxmin()\n",
        "# MomentTensor object\n",
        "best_mt = grid_dev.get(idx)\n",
        "# dictionary of lune parameters\n",
        "lune_dict = grid_dev.get_dict(idx)\n",
        "\n",
        "print('Generating figures...\\n')\n",
        "\n",
        "plot_data_greens2(event_id+'Dev_waveforms.png',\n",
        "    data_bw, data_sw, greens_bw, greens_sw, process_bw, process_sw,\n",
        "    misfit_bw, misfit_sw, stations, origin, best_mt, lune_dict)\n",
        "\n",
        "\n",
        "plot_beachball(event_id+'Dev_beachball.png',\n",
        "    best_mt, stations, origin)\n",
        "\n",
        "\n",
        "plot_misfit_dc(event_id+'Dev_DC_misfit.png', results_dev)\n",
        "\n",
        "plot_misfit_lune(event_id+'Dev_Lune_misfit_tradeoffs.png', results_dev, show_tradeoffs=True, plot_type='colormesh')"
      ],
      "metadata": {
        "id": "V3HQFoLXC6J_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "miVLF91Sl7qe"
      },
      "source": [
        "# 2.0.0 Running the code in parallel\n",
        "`MTUQ` has been designed with HPC applications in mind. It adopts a parallelization based on grid partitioning across processes, which offers good scaling with the number of CPU cores (grid search evaluation being independent, there is only very minimal communication between processes, except when gathering results).\n",
        "\n",
        "In Google Colab, we cannot guarantee that all of you will have access to better-specced machines on a free account, so we will have to work with the default Runtime, which comes with minimal resources: 2 vCPU.\n",
        "\n",
        "*Essentially, we have access to a single physical CPU core, split into two logical processors by using hyperthreading. Not ideal.*\n",
        "\n",
        "This will serve as a demonstration of how to use `MTUQ` in parallel, but don't expect a significant performance boost on Google Colab.\n",
        "\n",
        "The first chunk of code here will display the available resources (CPU0 and CUP1)\n",
        "\n",
        "The second will install mpi4py (the `MPI` module wrapper for Python) and run the Full Moment tensor grid search on the two available vCPUs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rvIsYsI-4xcc"
      },
      "outputs": [],
      "source": [
        "# First, let's check the number of available CPU on this machine\n",
        "from psutil import *\n",
        "print(\"Number of CPU: \", cpu_count())\n",
        "# This code will return the CPU info\n",
        "!cat /proc/cpuinfo\n",
        "\n",
        "%pip install mpi4py\n",
        "%cd /content/workdir/2009_04_07/\n",
        "!mpirun --use-hwthread-cpus --allow-run-as-root python -u /content/mtuq/examples/GridSearch.FullMomentTensor.py\n",
        "# Because here we do not have more than a single physical core we have to use --use-hwthread-cpus, which allow using hyperthreading\n",
        "\n",
        "# On your local machine or cluster, you would typically run\n",
        "# mpirun -n $NUMBER_OF_CPU_CORES python -u path/to/mtuq/examples/GridSearch.FullMomentTensor.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U-fqCVR5pdTm"
      },
      "source": [
        "We can now check how changing the grid affects the moment tensor solution. Let's have a look at the figures in /content/workdir/2009_04_07.\n",
        "\n",
        "Since we've also saved the results array as a NetCDF file, we can load it and generate another figure:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WB5_i7lbvbbM"
      },
      "outputs": [],
      "source": [
        "from mtuq import open_ds\n",
        "from mtuq.graphics import plot_misfit_lune\n",
        "\n",
        "results_fmt = open_ds('/content/workdir/2009_04_07/20090407201255351FMT_misfit.nc', format='NetCDF')\n",
        "\n",
        "print(results_fmt)\n",
        "\n",
        "plot_misfit_lune('20090407201255351FMT_misfit_tradeoffs.png', results_fmt, show_tradeoffs=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H6SXuvKtp0AG"
      },
      "source": [
        "# 3.0.0 Inverting for a new event from scratch\n",
        "\n",
        "In the following, we'll introduce our tool of choice to fetch and pre-process waveform data, which is also part of the SCOPED family of tools: [`PySEP`](https://github.com/adjtomo/pysep)\n",
        "\n",
        "Pysep fetches data, applies minimal processing, populates header information, and has the option to generate MTUQ-compatible weight files.\n",
        "\n",
        "Let's have a look at an event. Since we will be using a local Axisem Green's Function database with a 1D model for Southern California (from [Dreger and Helmberger (1990), Table 1](https://pubs.geoscienceworld.org/ssa/bssa/article/80/5/1162/119338/Broadband-modeling-of-local-earthquakes)), we select an event in this region: [M 4.9 - 17km ESE of Anza, CA](https://earthquake.usgs.gov/earthquakes/eventpage/ci39126079/executive), which is a Strike-skip event that occurred along the San Jacinto Fault.\n",
        "\n",
        "This event was also featured in the 2022 Workshop; we are using it again because it is an ideal dataset with a very good signal-to-noise ratio."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vELymNvszFUJ",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title 3.1.0 Let's download PySEP\n",
        "%%capture\n",
        "%cd /content\n",
        "!git clone https://github.com/adjtomo/pysep.git --depth 1\n",
        "\n",
        "# We're adding a line to the 2022 workshop config file here (PySEP has changed quite a lot since then!)\n",
        "import os\n",
        "import yaml\n",
        "# Define the file path and the line to be added\n",
        "file_path = \"/content/pysep/pysep/configs/mtuq_workshop_2022/2020-04-04T015318_SOUTHERN_CALIFORNIA.yaml\"\n",
        "line_to_add = \"write_files: 'inv,event,stream,sac,config_file,station_list,weights_dist'\"\n",
        "\n",
        "# Check if the file exists\n",
        "if not os.path.exists(file_path):\n",
        "    print(f\"File {file_path} does not exist.\")\n",
        "else:\n",
        "    # Load the YAML file\n",
        "    with open(file_path, 'r') as file:\n",
        "        yaml_data = yaml.safe_load(file)\n",
        "\n",
        "    # Add the line if it's not already present\n",
        "    if \"write_files\" not in yaml_data or yaml_data[\"write_files\"] != 'inv,event,stream,sac,config_file,station_list,weights_dist':\n",
        "        yaml_data[\"write_files\"] = 'inv,event,stream,sac,config_file,station_list,weights_dist'\n",
        "\n",
        "    # Change the value of resample_freq\n",
        "    if 'resample_freq' in yaml_data:\n",
        "        yaml_data['resample_freq'] = 10\n",
        "\n",
        "    if 'seconds_before_event' in yaml_data:\n",
        "        yaml_data['seconds_before_event'] = 100\n",
        "\n",
        "    if 'seconds_after_event' in yaml_data:\n",
        "        yaml_data['seconds_after_event'] = 300\n",
        "\n",
        "    # Save the modified YAML back to the file\n",
        "    with open(file_path, 'w') as file:\n",
        "        yaml.dump(yaml_data, file, default_flow_style=False)\n",
        "\n",
        "    print(\"YAML file updated successfully.\")\n",
        "\n",
        "\n",
        "%mkdir /content/workdir/data/\n",
        "%cd /content/workdir/data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RrtOi3QdakW2"
      },
      "source": [
        "The easiest way to use PySEP is to use its config files. These unstructured `.yaml` files allow users to provide needed information (origin time, location, depth, etc.) and override default input parameters (min-max distance to the event, min-max azimuth, network code, channel, etc.).\n",
        "\n",
        "While we get our data ready, we'll be in `/config/workdir/data`.\n",
        "\n",
        "Pysep can generate a default config file, which is a good way to start a new project:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kKyjmWx0e8w1"
      },
      "outputs": [],
      "source": [
        "!pysep -W\n",
        "!cat /content/workdir/data/pysep_config.yaml"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FvnYVaqRfE6b"
      },
      "source": [
        "Let us compare this template with the completed config file for the 2020-04-04 SJF earthquake. We would populate some of these infos directly with the [catalog origin](https://earthquake.usgs.gov/earthquakes/eventpage/ci39126079/origin/detail).\n",
        "\n",
        "### 3.2.0 Writing the PySEP config file\n",
        "\n",
        "*The next cell will display an HTML-based file difference, which is hard to read when the Colab UI is in dark mode. You can switch to light mode by clicking on the cog icon in the upper right of your screen and changing the Theme to light*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5v-fXoH1bXVZ"
      },
      "outputs": [],
      "source": [
        "import difflib\n",
        "import yaml\n",
        "from IPython.display import display, HTML\n",
        "\n",
        "\n",
        "template_file = '/content/workdir/data/pysep_config.yaml'\n",
        "completed_file = '/content/pysep/pysep/configs/mtuq_workshop_2022/2020-04-04T015318_SOUTHERN_CALIFORNIA.yaml'\n",
        "\n",
        "file_names = [template_file, completed_file]\n",
        "\n",
        "# Read the YAML files\n",
        "with open(file_names[0], 'r') as file1, open(file_names[1], 'r') as file2:\n",
        "    data1 = yaml.safe_load(file1)\n",
        "    data2 = yaml.safe_load(file2)\n",
        "\n",
        "# Convert the YAML data to pretty-printed strings\n",
        "pretty_yaml1 = yaml.dump(data1, default_flow_style=False)\n",
        "pretty_yaml2 = yaml.dump(data2, default_flow_style=False)\n",
        "\n",
        "# Generate the HTML diff\n",
        "html_diff = difflib.HtmlDiff().make_file(pretty_yaml1.splitlines(), pretty_yaml2.splitlines(), fromdesc=file_names[0], todesc=file_names[1])\n",
        "\n",
        "# Display the diff\n",
        "display(HTML(html_diff))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As you can see, only a few fields need to be filled in to download a dataset. These relate to the event's location and origin time and the networks/stations/channels we are interested in.\n",
        "It is important to specify we want to write out the and `weights_dist` (weight file sorted by distance) along with other outputs, as well as the `RTZ` rotated traces expected by `MTUQ`.\n",
        "\n",
        "We can proceed directly to the downloading stage with the following in-line `PySEP` command using the pre-completed config file.\n",
        "\n",
        "*This cell might not run on the first attemp, due to server-side issues. If you get an error, simply re-run this cell.*"
      ],
      "metadata": {
        "id": "VlDIAT3dRmZJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hNnU-5O2zp6d"
      },
      "outputs": [],
      "source": [
        "%cd /content/workdir/data/\n",
        "!pysep -c /content/pysep/pysep/configs/mtuq_workshop_2022/2020-04-04T015318_SOUTHERN_CALIFORNIA.yaml -o"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Before we move on, let's have a look at the data we just downloaded. First, let's look at the default record section that `PySEP` generates: /content/workdir/data/2020-04-04T015318_SOUTHERN_CALIFORNIA/record_section.png\n",
        "\n",
        "`PySEP` comes with `RecSec`, which is a record-section plotting utility that we can use to inspect the downloaded dataset. Here are a couple of example record sections we can generate (they will be located in: /content/workdir/data/2020-04-04T015318_SOUTHERN_CALIFORNIA/)."
      ],
      "metadata": {
        "id": "m-qtAWclMm0J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# First, a record section focused on body waves (ZR components)\n",
        "# with high-frequency content. recsec_1.png\n",
        "!recsec --pysep_path ./2020-04-04T015318_SOUTHERN_CALIFORNIA/SAC -o --scale_by 'normalize' --min_period_s 0.1 --max_period 8  --integrate 1 --component ZR --save ./2020-04-04T015318_SOUTHERN_CALIFORNIA/recsec_1.png\n",
        "\n",
        "# Then a record section for Rayleigh waves (ZR) at longer period.\n",
        "# recsec_2.png\n",
        "!recsec --pysep_path ./2020-04-04T015318_SOUTHERN_CALIFORNIA/SAC -o --scale_by 'normalize' --min_period_s 4 --max_period 50  --integrate 1 --component ZR --save ./2020-04-04T015318_SOUTHERN_CALIFORNIA/recsec_2.png\n",
        "\n",
        "# Finally, the Love waves (T) at longer period. We also include a linear moveout\n",
        "# of 3.4km/s. recsec_3.png\n",
        "!recsec --pysep_path ./2020-04-04T015318_SOUTHERN_CALIFORNIA/SAC -o --scale_by 'normalize' --min_period_s 4 --max_period 50  --integrate 1 --component T --move_out 3.4 --save ./2020-04-04T015318_SOUTHERN_CALIFORNIA/recsec_3.png\n"
      ],
      "metadata": {
        "id": "2wdZOAH7QamF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that we have a new dataset, we are going to download a pre-computed [Axisem](https://github.com/geodynamics/axisem) Green's function database for the Southern California region. The database region has a 5° distance extent and a maximum depth of 70km. Having a small chunk of the domain allows for keeping the database at a reasonable size. For 300s signals with a dominant period of 1s, the database is about 7.3 Gb.\n"
      ],
      "metadata": {
        "id": "5xl9Vbv_UdWs"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lrp8-UF3b0eJ",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title 3.2.1 Downloading the Axisem database\n",
        "!mkdir /content/workdir/greens\n",
        "%cd /content/workdir/greens\n",
        "\n",
        "# We will fetch the archive from different free file-sharing services (GDrive, HuggingFace) at random\n",
        "# to balance the downloads\n",
        "if not os.path.isfile('/content/workdir/greens/socal1D.zip'):\n",
        "  db_key = np.random.randint(0,5)\n",
        "  if db_key == 0:\n",
        "    !gdown https://drive.google.com/file/d/1f3l6hrPMyA7GImNoEupYAkmtqTnjinaY/view?usp=sharing --fuzzy\n",
        "  elif db_key == 1:\n",
        "    !wget https://huggingface.co/datasets/jthurin/scak_axisem_2s/resolve/main/socal1D.zip\n",
        "  elif db_key == 2:\n",
        "    !gdown https://drive.google.com/file/d/1ZU7dfVbUgtTy1C2COct3GrgQfhNGbmAz/view?usp=sharing --fuzzy\n",
        "  elif db_key == 3:\n",
        "    !gdown https://drive.google.com/file/d/1iljB0vFHEm4HeG2Dg-UhjtECrkH3LeiZ/view?usp=share_link --fuzzy\n",
        "    !mv   ./socal1D_1.zip ./socal1D.zip\n",
        "  elif db_key == 4:\n",
        "    !gdown https://drive.google.com/file/d/1VNu4MDe42JjvZdd-_wc3uvQl4punEnnc/view?usp=sharing --fuzzy\n",
        "    !mv   ./socal1D_2.zip ./socal1D.zip\n",
        "  !unzip ./socal1D.zip && mv /content/workdir/greens/store/wf/instaseis_databases/socal1D_1s_5_70_70_300s/ /content/workdir/greens && rm -fr /content/workdir/greens/store"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We have the dataset and the Green's function, so let's bake an `MTUQ` script.\n",
        "\n",
        "### 3.3.0 Double Couple inversion with depth-search\n",
        "\n",
        "In the next cell is a \"template-like\" `MTUQ` script. We will perform a double-couple inversion with a few magnitudes and depth grid points.\n",
        "\n",
        "We will go through it before running it, as it will serve as a starting point for the next part of the workshop where you will download data on your own, fill-in your own script, check the results, modify the input weight file, etc.\n",
        "\n",
        "This will take about **6 minutes**."
      ],
      "metadata": {
        "id": "CspT20-SvP8R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir /content/workdir/2020_04_04/\n",
        "%cd /content/workdir/2020_04_04/\n",
        "\n",
        "# Regular import here (it was already initialized earlier).\n",
        "# It is included if we have to restart the runtime during the workshop.\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "from mtuq import read, open_db, download_greens_tensors\n",
        "from mtuq.event import Origin\n",
        "from mtuq.graphics import plot_data_greens2, plot_beachball, plot_misfit_dc, plot_misfit_depth\n",
        "from mtuq.grid import DoubleCoupleGridRegular, FullMomentTensorGridSemiregular\n",
        "from mtuq.grid_search import grid_search\n",
        "from mtuq.misfit import Misfit\n",
        "from mtuq.process_data import ProcessData\n",
        "from mtuq.util import fullpath, merge_dicts, save_json\n",
        "from mtuq.util.cap import parse_station_codes, Trapezoid\n",
        "\n",
        "\n",
        "path_data_socal = '/content/workdir/data/2020-04-04T015318_SOUTHERN_CALIFORNIA/SAC/*[ZRT].sac'\n",
        "path_weight_socal = '/content/workdir/data/2020-04-04T015318_SOUTHERN_CALIFORNIA/weights.dat'\n",
        "model = 'ak135' # This is the model name for the taup-computed picks.\n",
        "event_id = '2020-04-04T015318_SOCAL'\n",
        "\n",
        "# Define the data-processing\n",
        "\n",
        "process_bw = ProcessData(\n",
        "    filter_type='Bandpass',\n",
        "    freq_min= 1/10,\n",
        "    freq_max= 1/2.5,\n",
        "    pick_type='taup',\n",
        "    taup_model=model,\n",
        "    window_type='body_wave',\n",
        "    window_length=15.,\n",
        "    capuaf_file=path_weight_socal,\n",
        "    )\n",
        "\n",
        "process_sw = ProcessData(\n",
        "    filter_type='Bandpass',\n",
        "    freq_min=1/30,\n",
        "    freq_max=1/16,\n",
        "    pick_type='taup',\n",
        "    taup_model=model,\n",
        "    window_type='surface_wave',\n",
        "    window_length=120.,\n",
        "    capuaf_file=path_weight_socal,\n",
        "    )\n",
        "\n",
        "# Define the misfit\n",
        "#\n",
        "# For our objective function, we will use a sum of body and surface wave\n",
        "# contributions\n",
        "#\n",
        "\n",
        "\n",
        "misfit_bw = Misfit(\n",
        "    norm='L2',\n",
        "    time_shift_min=-5.,\n",
        "    time_shift_max=+5.,\n",
        "    time_shift_groups=['ZR'],\n",
        "    )\n",
        "\n",
        "misfit_sw = Misfit(\n",
        "    norm='L2',\n",
        "    time_shift_min=-20.,\n",
        "    time_shift_max=+20.,\n",
        "    time_shift_groups=['ZR','T'],\n",
        "    )\n",
        "\n",
        "#\n",
        "# User-supplied weights control how much each station contributes to the\n",
        "# objective function\n",
        "#\n",
        "\n",
        "station_id_list = parse_station_codes(path_weight_socal)\n",
        "\n",
        "#\n",
        "# Next, we specify the moment tensor grid and source-time function\n",
        "#\n",
        "\n",
        "grid = DoubleCoupleGridRegular(\n",
        "    npts_per_axis=40, # I advise no more than 40 on Colab\n",
        "    magnitudes=[4.8, 4.9, 5.0])\n",
        "\n",
        "wavelet = Trapezoid(\n",
        "    magnitude= 4.9)\n",
        "\n",
        "# We will work with a fixed origin for now:\n",
        "\n",
        "origin = Origin({\n",
        "    'time': '2020-04-04T01:53:18.920000Z',\n",
        "    'latitude': 33.49,\n",
        "    'longitude': -116.506,\n",
        "    'depth_in_m': 10500.0,\n",
        "    })\n",
        "\n",
        "depths = np.array(\n",
        "      # depth in meters\n",
        "    [6500,8500,10500.0,12500,14500])\n",
        "\n",
        "# This loop creates a list of Origin objects, updating the depth value for each entry\n",
        "origins = []\n",
        "for depth in depths:\n",
        "    origins += [origin.copy()]\n",
        "    setattr(origins[-1], 'depth_in_m', depth)\n",
        "\n",
        "# Data import\n",
        "print('Reading data...\\n')\n",
        "data = read(path_data_socal, format='sac',\n",
        "    event_id=event_id,\n",
        "    station_id_list=station_id_list,\n",
        "    tags=['units:m', 'type:velocity'])\n",
        "\n",
        "\n",
        "data.sort_by_distance()\n",
        "stations = data.get_stations()\n",
        "\n",
        "\n",
        "print('Processing data...\\n')\n",
        "data_bw = data.map(process_bw)\n",
        "data_sw = data.map(process_sw)\n",
        "\n",
        "# Green's function import\n",
        "print('Reading Greens functions...\\n')\n",
        "\n",
        "# Here's the main difference from the previous script: we load the entire local\n",
        "# Green's function database, and then fetch the stream we are interested in, instead\n",
        "# of downloading from syngine. This loads the GFs for each entries in origins.\n",
        "\n",
        "db = open_db('/content/workdir/greens/socal1D_1s_5_70_70_300s/', format='AxiSEM')\n",
        "greens = db.get_greens_tensors(stations, origins)\n",
        "\n",
        "print('Processing Greens functions...\\n')\n",
        "greens.convolve(wavelet)\n",
        "greens_bw = greens.map(process_bw)\n",
        "greens_sw = greens.map(process_sw)\n",
        "\n",
        "\n",
        "print('Evaluating body wave misfit...\\n')\n",
        "results_bw = grid_search(\n",
        "    data_bw, greens_bw, misfit_bw, origins, grid)\n",
        "print('Evaluating surface wave misfit...\\n')\n",
        "results_sw = grid_search(\n",
        "    data_sw, greens_sw, misfit_sw, origins, grid)\n",
        "\n",
        "# Combining the two misfit contributions\n",
        "results = results_bw + results_sw\n",
        "\n",
        "#\n",
        "# Collect information about best-fitting source\n",
        "#\n",
        "\n",
        "# Index of the best origin\n",
        "origin_idx = results.origin_idxmin()\n",
        "best_origin = origins[origin_idx]\n",
        "\n",
        "# Index of the best source solution\n",
        "source_idx = results.source_idxmin()\n",
        "best_mt = grid.get(source_idx)\n",
        "\n",
        "# dictionary of lune parameters\n",
        "lune_dict = grid.get_dict(source_idx)\n",
        "\n",
        "#\n",
        "# Generate figures and save results\n",
        "#\n",
        "\n",
        "print('Generating figures...\\n')\n",
        "# Waveform plot\n",
        "plot_data_greens2(event_id+'DC_waveforms.png',\n",
        "    data_bw, data_sw, greens_bw, greens_sw, process_bw, process_sw,\n",
        "    misfit_bw, misfit_sw, stations, best_origin, best_mt, lune_dict)\n",
        "\n",
        "# Beachball plot\n",
        "plot_beachball(event_id+'DC_beachball.png',\n",
        "    best_mt, stations, best_origin)\n",
        "\n",
        "# Double-couple misfit plot\n",
        "plot_misfit_dc(event_id+'DC_misfit.png', results)\n",
        "\n",
        "# Depth-misfit plot\n",
        "plot_misfit_depth(event_id+'DC_misfit_depth.png', results, origins, show_tradeoffs=True, show_magnitudes=True)"
      ],
      "metadata": {
        "id": "9-gMc0q7r7Jz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's take some time to check the figures in /content/workdir/2020_04_04 before we move on.\n",
        "\n",
        "### 3.4.0 Full moment tensor with depth search\n",
        "\n",
        "We will re-run the grid search to compare those results with a full moment tensor inversion, changing only the grid. The grid is slightly larger than in the previous cell ($1.05*10^6$ instead of $9.6*10^5$), so we can expect about **6 min** of runtime. (Don't worry, it will be our longest downtime)."
      ],
      "metadata": {
        "id": "w4gNoXOGKdYv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from mtuq.graphics import plot_misfit_lune\n",
        "\n",
        "# Here we're only changing the grid, so we can directly run the grid search and plotting\n",
        "grid = FullMomentTensorGridSemiregular(magnitudes=[4.8],\n",
        "                                       npts_per_axis=10)\n",
        "\n",
        "print('Evaluating body wave misfit...\\n')\n",
        "results_bw = grid_search(\n",
        "    data_bw, greens_bw, misfit_bw, origins, grid)\n",
        "print('Evaluating surface wave misfit...\\n')\n",
        "results_sw = grid_search(\n",
        "    data_sw, greens_sw, misfit_sw, origins, grid)\n",
        "\n",
        "\n",
        "# Combining the two misfit contributions\n",
        "results = results_bw + results_sw\n",
        "\n",
        "#\n",
        "# Collect information about best-fitting source\n",
        "#\n",
        "\n",
        "# Index of the best origin\n",
        "origin_idx = results.origin_idxmin()\n",
        "best_origin = origins[origin_idx]\n",
        "\n",
        "# Index of the best source solution\n",
        "source_idx = results.source_idxmin()\n",
        "best_mt = grid.get(source_idx)\n",
        "\n",
        "# dictionary of lune parameters\n",
        "lune_dict = grid.get_dict(source_idx)\n",
        "\n",
        "# Lune plots (misfit and beachball tradeoffs)\n",
        "plot_misfit_lune(event_id+'FMT_Lune_misfit.png', results)\n",
        "plot_misfit_lune(event_id+'FMT_Lune_misfit_tradeoffs.png', results, show_tradeoffs=True)\n",
        "\n",
        "# Waveform plot\n",
        "plot_data_greens2(event_id+'FMT_waveforms.png',\n",
        "    data_bw, data_sw, greens_bw, greens_sw, process_bw, process_sw,\n",
        "    misfit_bw, misfit_sw, stations, best_origin, best_mt, lune_dict)\n",
        "\n",
        "# Beachball plot\n",
        "plot_beachball(event_id+'FMT_beachball.png',\n",
        "    best_mt, stations, best_origin)\n",
        "\n",
        "# Double-couple misfit plot\n",
        "plot_misfit_dc(event_id+'FMT_DC_misfit.png', results)\n",
        "\n",
        "# Depth-misfit plot\n",
        "plot_misfit_depth(event_id+'FMT_misfit_depth.png', results, origins, show_tradeoffs=True, show_magnitudes=True)"
      ],
      "metadata": {
        "id": "HZGEKKYdtRz6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Again, you can view the results in /content/workdir/2020_04_04.\n",
        "\n",
        "This concludes the guided part of this workshop. The next section will feature a hands-on case.\n",
        "\n",
        "# 4.0.0 Self-guided inversion\n",
        "\n",
        "In this section, you will be downloading data for a [M 4.6 - 2 km S of Roosevelt, Washington](https://earthquake.usgs.gov/earthquakes/eventpage/uw61535372/executive) and perform the inversion by yourself, following a few instructions and filling-in a template.\n",
        "\n",
        "I have selected this event because we can get close to a good fit almost from the get-go. The next cell will generate an empty file as a pattern."
      ],
      "metadata": {
        "id": "bZeNs6bPL-EM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/workdir/data\n",
        "!cp pysep_config.yaml 2019_07_12_WASHINGTON.yaml"
      ],
      "metadata": {
        "id": "mL4AeKdbjWxN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The previous cell generates an empty `PySEP` config file (`2019_07_12_WASHINGTON.yaml`) that you have to complete.\n",
        "\n",
        "You can check the config file from the previous example for reference:\n",
        "\n",
        "/content/pysep/pysep/configs/mtuq_workshop_2022/2020-04-04T015318_SOUTHERN_CALIFORNIA.yaml\n",
        "\n",
        "In order not to download too much data, here are a few constraints you should follow:\n",
        "\n",
        "- get data from the `UW,CN,X4,UO` networks only,\n",
        "- within 250 km of epicentral distance,\n",
        "- request the `HH?` channels (high-gain broadband stations).\n",
        "\n",
        "For future reference, if you need to find the available stations within a specific region of the world at a given time, you can use the [EarthScope SAGE network map](https://ds.iris.edu/gmap/).\n",
        "\n",
        "When you're done, you can run:g"
      ],
      "metadata": {
        "id": "GSvG7ktwu5GB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pysep -c ./2019_07_12_WASHINGTON.yaml -o"
      ],
      "metadata": {
        "id": "NVnvhJqovTbJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Before opening the data in `MTUQ`, you should **always have a look at the record sections**."
      ],
      "metadata": {
        "id": "zSH1PArjveVD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Raw vertical component - recsec_1.png\n",
        "!recsec --pysep_path ./2019-07-12T095138_WASHINGTON/SAC -o --scale_by 'geometric_spreading'  --integrate 1 --component Z --save ./2019-07-12T095138_WASHINGTON/recsec_1.png\n",
        "\n",
        "# Raw radial component - recsec_2.png\n",
        "!recsec --pysep_path ./2019-07-12T095138_WASHINGTON/SAC -o --scale_by 'geometric_spreading'  --integrate 1 --component R --save ./2019-07-12T095138_WASHINGTON/recsec_2.png\n",
        "\n",
        "# Raw transverse component - recsec_3.png\n",
        "!recsec --pysep_path ./2019-07-12T095138_WASHINGTON/SAC -o --scale_by 'geometric_spreading'  --integrate 1 --component T --save ./2019-07-12T095138_WASHINGTON/recsec_3.png\n"
      ],
      "metadata": {
        "id": "Do6-IRSgvnno"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Setting-up the weight files\n",
        "\n",
        "If you open the record sections, you will see a few stations with significant, long-period oscillations—we have enough data to discard them.\n",
        "\n",
        "Open the `weights.dat` file in the appropriate folder, and set these stations' weights to 0 (for all 5 data groups). By discarding them now, you won't have to download their Green's functions.\n",
        "\n",
        "When ready to run the inversion, fill in the `XXXX` in the next cell. Running the cell will take a bit of time, as it will have to retrieve a few dozen stations.\n",
        "\n",
        "The 'Origin' page of the event list the depth at 28.8km, while the 'Moment tensor' page list a depth of 35.5km. Pick one, and we will discuss the results at the end.\n",
        "\n",
        "(Here is what a quick double-couple depth search returns, with magnitudes ranging from 4.4 to 4.7:)\n",
        "<figure>\n",
        "<center>\n",
        "<img src=\"https://drive.google.com/uc?id=1KdVKqNfry68r_uahH9BbXrL-UpwkU1fO\" width=\"400\"  alt=\"Result of a DC depth search\">\n",
        "</center>\n",
        "</figure>"
      ],
      "metadata": {
        "id": "oWJsKUGww67v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir /content/workdir/2019_07_12/\n",
        "%cd /content/workdir/2019_07_12/\n",
        "\n",
        "# Regular import here (it was already initialized earlier).\n",
        "# It is included if we have to restart the runtime during the workshop.\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "from mtuq import read, open_db, download_greens_tensors\n",
        "from mtuq.event import Origin\n",
        "from mtuq.graphics import plot_data_greens2, plot_beachball, plot_misfit_dc, plot_misfit_lune\n",
        "from mtuq.grid import DoubleCoupleGridRegular, FullMomentTensorGridSemiregular\n",
        "from mtuq.grid_search import grid_search\n",
        "from mtuq.misfit import Misfit\n",
        "from mtuq.process_data import ProcessData\n",
        "from mtuq.util import fullpath, merge_dicts, save_json\n",
        "from mtuq.util.cap import parse_station_codes, Trapezoid\n",
        "\n",
        "\n",
        "path_data = 'XXXX'\n",
        "path_weight = 'XXXX'\n",
        "model = 'ak135' # This is the model name for the taup-computed picks.\n",
        "event_id = '2019-07-12T095138_WASHINGTON'\n",
        "\n",
        "# Define the data-processing\n",
        "\n",
        "process_bw = ProcessData(\n",
        "    filter_type='Bandpass',\n",
        "    freq_min= XXX,\n",
        "    freq_max= XXX,\n",
        "    pick_type='taup',\n",
        "    taup_model=model,\n",
        "    window_type='body_wave',\n",
        "    window_length=XXX,\n",
        "    capuaf_file=path_weight,\n",
        "    )\n",
        "\n",
        "process_sw = ProcessData(\n",
        "    filter_type='Bandpass',\n",
        "    freq_min=XXX,\n",
        "    freq_max=XXXX,\n",
        "    pick_type='taup',\n",
        "    taup_model=model,\n",
        "    window_type='surface_wave',\n",
        "    window_length=XXX.,\n",
        "    capuaf_file=path_weight,\n",
        "    )\n",
        "\n",
        "# Define the misfit\n",
        "#\n",
        "# For our objective function, we will use a sum of body and surface wave\n",
        "# contributions\n",
        "#\n",
        "\n",
        "\n",
        "misfit_bw = Misfit(\n",
        "    norm='L2',\n",
        "    time_shift_min=XXX,\n",
        "    time_shift_max=XXX,\n",
        "    time_shift_groups=['ZR'],\n",
        "    )\n",
        "\n",
        "misfit_sw = Misfit(\n",
        "    norm='L2',\n",
        "    time_shift_min=XXX,\n",
        "    time_shift_max=XXX,\n",
        "    time_shift_groups=['ZR','T'],\n",
        "    )\n",
        "\n",
        "#\n",
        "# User-supplied weights control how much each station contributes to the\n",
        "# objective function\n",
        "#\n",
        "\n",
        "station_id_list = parse_station_codes(path_weight)\n",
        "\n",
        "#\n",
        "# Next, we specify the moment tensor grid and source-time function\n",
        "#\n",
        "\n",
        "grid = DoubleCoupleGridRegular(\n",
        "    npts_per_axis=XX, # I advise no more than 40 on Colab for DC\n",
        "    magnitudes=[XXX])\n",
        "\n",
        "# or\n",
        "# grid = FullMomentTensorGridSemiregular(\n",
        "#     npts_per_axis=XX, # I advise no more than 10 on Colab for FMT with a single magnitude\n",
        "#     magnitudes = [XXX])\n",
        "\n",
        "wavelet = Trapezoid(\n",
        "    magnitude= XXX)\n",
        "\n",
        "# We will work with a fixed origin.\n",
        "\n",
        "origin = Origin({\n",
        "    'time': 'XXX',\n",
        "    'latitude': XXX,\n",
        "    'longitude': XXX,\n",
        "    'depth_in_m': XXX,\n",
        "    })\n",
        "\n",
        "# Data import\n",
        "print('Reading data...\\n')\n",
        "data = read(path_data, format='sac',\n",
        "    event_id=event_id,\n",
        "    station_id_list=station_id_list,\n",
        "    tags=['units:m', 'type:velocity'])\n",
        "\n",
        "\n",
        "data.sort_by_distance()\n",
        "stations = data.get_stations()\n",
        "\n",
        "\n",
        "print('Processing data...\\n')\n",
        "data_bw = data.map(process_bw)\n",
        "data_sw = data.map(process_sw)\n",
        "\n",
        "# Green's function import\n",
        "print('Reading Greens functions...\\n')\n",
        "greens = download_greens_tensors(stations, origin, model)\n",
        "\n",
        "print('Processing Greens functions...\\n')\n",
        "greens.convolve(wavelet)\n",
        "greens_bw = greens.map(process_bw)\n",
        "greens_sw = greens.map(process_sw)\n",
        "\n",
        "\n",
        "print('Evaluating body wave misfit...\\n')\n",
        "results_bw = grid_search(\n",
        "    data_bw, greens_bw, misfit_bw, origin, grid)\n",
        "print('Evaluating surface wave misfit...\\n')\n",
        "results_sw = grid_search(\n",
        "    data_sw, greens_sw, misfit_sw, origin, grid)\n",
        "\n",
        "# Combining the two misfit contributions\n",
        "results = XXX\n",
        "\n",
        "#\n",
        "# Collect information about best-fitting source\n",
        "#\n",
        "\n",
        "# Index of the best source solution\n",
        "source_idx = results.source_idxmin()\n",
        "best_mt = grid.get(source_idx)\n",
        "\n",
        "# dictionary of lune parameters\n",
        "lune_dict = grid.get_dict(source_idx)\n",
        "\n",
        "#\n",
        "# Generate figures and save results\n",
        "#\n",
        "\n",
        "print('Generating figures...\\n')\n",
        "# Waveform plot\n",
        "plot_data_greens2(event_id+'_waveforms.png',\n",
        "    data_bw, data_sw, greens_bw, greens_sw, process_bw, process_sw,\n",
        "    misfit_bw, misfit_sw, stations, origin, best_mt, lune_dict)\n",
        "\n",
        "# Beachball plot\n",
        "plot_beachball(event_id+'_beachball.png',\n",
        "    best_mt, stations, origin)\n",
        "\n",
        "# Double-couple misfit plot\n",
        "plot_misfit_dc(event_id+'DC_misfit.png', results)\n",
        "\n",
        "# and\n",
        "# plot_misfit_lune(event_id+'FMT_misfit.png', results)\n",
        "# plot_misfit_lune(event_id+'FMT_misfit_tradeoffs.png', results, show_tradeoffs=True)"
      ],
      "metadata": {
        "id": "19tPVpj3dH5O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The final output figures will be located in /content/workdir/2019_07_12/.\n",
        "\n",
        "I now encourage you to play with the filtering parameters, window size, weight file, etc., just so you see the variability we can expect with a Full Moment tensor when the Earth model is not ideal."
      ],
      "metadata": {
        "id": "UE-Dl7KmcOVT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# What's next?\n",
        "You can try to run `MTUQ`'s [installation instructions](https://uafgeotools.github.io/mtuq/install/index.html) on your local machine and run the examples in the `/mtuq/examples/` folder.  \n",
        "*Note that the install instructions are **not** valid for this colab environment.*\n",
        "\n",
        "Or try out `MTUQ` directly in the Docker container (brought to you by SCOPED!):  \n",
        "```bash\n",
        "docker pull ghcr.io/seisscoped/mtuq:ubuntu20.04\n",
        "```\n",
        "Stay tuned for future updates (black-box optimization method, visualization libraries, model and data uncertainty, etc.)!"
      ],
      "metadata": {
        "id": "EHrIaMnkumMy"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}